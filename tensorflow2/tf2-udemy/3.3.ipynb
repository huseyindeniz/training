{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow\n",
    "# direct tensorflow installation throws tensorboard version error on my env\n",
    "# so install tensorboard 2.0.0 first\n",
    "# ! pip install tensorboard==2.0.0\n",
    "# ! pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of 'data'\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: it is a Bunch object\n",
    "# this basically acts like a dictionary where you can treat the keys lie attributes\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'data' (the attribute) means the inout data\n",
    "data.data.shape\n",
    "# it has 569 samples, 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'targets'\n",
    "data.target\n",
    "# note how the targets are just 0s and 1s\n",
    "# normally, when you have K targets, they are labeled 0..K-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their meaning is not lost\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are also 569 corresponding targets\n",
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also determine the meaning of each feature\n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would put all of our imports at the top\n",
    "# but this lets us tell a story\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test sets\n",
    "# this lets us simulate how our model will perform in the future\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# you'll learn why scaling is needed in a later course\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/3-3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/500\n",
      "381/381 [==============================] - 1s 1ms/sample - loss: 0.7794 - accuracy: 0.5827 - val_loss: 0.6841 - val_accuracy: 0.6383\n",
      "Epoch 2/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.7195 - accuracy: 0.6194 - val_loss: 0.6233 - val_accuracy: 0.6702\n",
      "Epoch 3/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.6666 - accuracy: 0.6640 - val_loss: 0.5704 - val_accuracy: 0.6915\n",
      "Epoch 4/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.6190 - accuracy: 0.6955 - val_loss: 0.5266 - val_accuracy: 0.7447\n",
      "Epoch 5/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.5791 - accuracy: 0.7192 - val_loss: 0.4881 - val_accuracy: 0.7660\n",
      "Epoch 6/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.5427 - accuracy: 0.7375 - val_loss: 0.4560 - val_accuracy: 0.7872\n",
      "Epoch 7/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.5118 - accuracy: 0.7690 - val_loss: 0.4273 - val_accuracy: 0.8085\n",
      "Epoch 8/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.4842 - accuracy: 0.7822 - val_loss: 0.4023 - val_accuracy: 0.8404\n",
      "Epoch 9/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.4589 - accuracy: 0.7927 - val_loss: 0.3807 - val_accuracy: 0.8564\n",
      "Epoch 10/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.4364 - accuracy: 0.8110 - val_loss: 0.3615 - val_accuracy: 0.8617\n",
      "Epoch 11/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.4164 - accuracy: 0.8136 - val_loss: 0.3442 - val_accuracy: 0.8617\n",
      "Epoch 12/500\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.3982 - accuracy: 0.8320 - val_loss: 0.3282 - val_accuracy: 0.8777\n",
      "Epoch 13/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.65 - 0s 117us/sample - loss: 0.3818 - accuracy: 0.8346 - val_loss: 0.3135 - val_accuracy: 0.8830\n",
      "Epoch 14/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.3661 - accuracy: 0.8478 - val_loss: 0.3005 - val_accuracy: 0.8830\n",
      "Epoch 15/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.3516 - accuracy: 0.8583 - val_loss: 0.2888 - val_accuracy: 0.8936\n",
      "Epoch 16/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.3389 - accuracy: 0.8635 - val_loss: 0.2776 - val_accuracy: 0.8936\n",
      "Epoch 17/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.3266 - accuracy: 0.8635 - val_loss: 0.2678 - val_accuracy: 0.8989\n",
      "Epoch 18/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.3157 - accuracy: 0.8635 - val_loss: 0.2581 - val_accuracy: 0.8989\n",
      "Epoch 19/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.3054 - accuracy: 0.8688 - val_loss: 0.2490 - val_accuracy: 0.9096\n",
      "Epoch 20/500\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.2952 - accuracy: 0.8740 - val_loss: 0.2411 - val_accuracy: 0.9149\n",
      "Epoch 21/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.2861 - accuracy: 0.8793 - val_loss: 0.2337 - val_accuracy: 0.9202\n",
      "Epoch 22/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.2776 - accuracy: 0.8819 - val_loss: 0.2268 - val_accuracy: 0.9202\n",
      "Epoch 23/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.2699 - accuracy: 0.8898 - val_loss: 0.2200 - val_accuracy: 0.9255\n",
      "Epoch 24/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.2625 - accuracy: 0.8924 - val_loss: 0.2137 - val_accuracy: 0.9255\n",
      "Epoch 25/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.2554 - accuracy: 0.9003 - val_loss: 0.2080 - val_accuracy: 0.9255\n",
      "Epoch 26/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.2487 - accuracy: 0.9003 - val_loss: 0.2026 - val_accuracy: 0.9309\n",
      "Epoch 27/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.2427 - accuracy: 0.9081 - val_loss: 0.1976 - val_accuracy: 0.9309\n",
      "Epoch 28/500\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.2369 - accuracy: 0.9160 - val_loss: 0.1929 - val_accuracy: 0.9362\n",
      "Epoch 29/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.2315 - accuracy: 0.9213 - val_loss: 0.1884 - val_accuracy: 0.9362\n",
      "Epoch 30/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.2264 - accuracy: 0.9239 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 31/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.2215 - accuracy: 0.9265 - val_loss: 0.1803 - val_accuracy: 0.9362\n",
      "Epoch 32/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.2169 - accuracy: 0.9291 - val_loss: 0.1765 - val_accuracy: 0.9362\n",
      "Epoch 33/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.2126 - accuracy: 0.9318 - val_loss: 0.1729 - val_accuracy: 0.9362\n",
      "Epoch 34/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.2087 - accuracy: 0.9344 - val_loss: 0.1693 - val_accuracy: 0.9415\n",
      "Epoch 35/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.2046 - accuracy: 0.9344 - val_loss: 0.1662 - val_accuracy: 0.9415\n",
      "Epoch 36/500\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.2010 - accuracy: 0.9396 - val_loss: 0.1631 - val_accuracy: 0.9415\n",
      "Epoch 37/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.1976 - accuracy: 0.9423 - val_loss: 0.1601 - val_accuracy: 0.9468\n",
      "Epoch 38/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.1941 - accuracy: 0.9449 - val_loss: 0.1575 - val_accuracy: 0.9468\n",
      "Epoch 39/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.1910 - accuracy: 0.9449 - val_loss: 0.1548 - val_accuracy: 0.9468\n",
      "Epoch 40/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.1878 - accuracy: 0.9449 - val_loss: 0.1523 - val_accuracy: 0.9521\n",
      "Epoch 41/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.1849 - accuracy: 0.9475 - val_loss: 0.1500 - val_accuracy: 0.9574\n",
      "Epoch 42/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1822 - accuracy: 0.9475 - val_loss: 0.1476 - val_accuracy: 0.9628\n",
      "Epoch 43/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1795 - accuracy: 0.9475 - val_loss: 0.1454 - val_accuracy: 0.9628\n",
      "Epoch 44/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1769 - accuracy: 0.9475 - val_loss: 0.1434 - val_accuracy: 0.9681\n",
      "Epoch 45/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1745 - accuracy: 0.9475 - val_loss: 0.1412 - val_accuracy: 0.9734\n",
      "Epoch 46/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.1721 - accuracy: 0.9475 - val_loss: 0.1393 - val_accuracy: 0.9734\n",
      "Epoch 47/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1699 - accuracy: 0.9475 - val_loss: 0.1374 - val_accuracy: 0.9734\n",
      "Epoch 48/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1677 - accuracy: 0.9501 - val_loss: 0.1357 - val_accuracy: 0.9734\n",
      "Epoch 49/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1655 - accuracy: 0.9501 - val_loss: 0.1340 - val_accuracy: 0.9734\n",
      "Epoch 50/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1635 - accuracy: 0.9501 - val_loss: 0.1323 - val_accuracy: 0.9734\n",
      "Epoch 51/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.1615 - accuracy: 0.9501 - val_loss: 0.1308 - val_accuracy: 0.9734\n",
      "Epoch 52/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.1596 - accuracy: 0.9501 - val_loss: 0.1293 - val_accuracy: 0.9734\n",
      "Epoch 53/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1578 - accuracy: 0.9501 - val_loss: 0.1277 - val_accuracy: 0.9734\n",
      "Epoch 54/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1560 - accuracy: 0.9501 - val_loss: 0.1263 - val_accuracy: 0.9734\n",
      "Epoch 55/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1543 - accuracy: 0.9501 - val_loss: 0.1249 - val_accuracy: 0.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1526 - accuracy: 0.9528 - val_loss: 0.1236 - val_accuracy: 0.9734\n",
      "Epoch 57/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.1509 - accuracy: 0.9528 - val_loss: 0.1223 - val_accuracy: 0.9734\n",
      "Epoch 58/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1494 - accuracy: 0.9528 - val_loss: 0.1211 - val_accuracy: 0.9734\n",
      "Epoch 59/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.1478 - accuracy: 0.9528 - val_loss: 0.1199 - val_accuracy: 0.9734\n",
      "Epoch 60/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.1464 - accuracy: 0.9528 - val_loss: 0.1187 - val_accuracy: 0.9734\n",
      "Epoch 61/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1449 - accuracy: 0.9528 - val_loss: 0.1175 - val_accuracy: 0.9734\n",
      "Epoch 62/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.1435 - accuracy: 0.9580 - val_loss: 0.1165 - val_accuracy: 0.9734\n",
      "Epoch 63/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.1422 - accuracy: 0.9580 - val_loss: 0.1154 - val_accuracy: 0.9734\n",
      "Epoch 64/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.1408 - accuracy: 0.9580 - val_loss: 0.1144 - val_accuracy: 0.9734\n",
      "Epoch 65/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.1395 - accuracy: 0.9580 - val_loss: 0.1134 - val_accuracy: 0.9734\n",
      "Epoch 66/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1383 - accuracy: 0.9580 - val_loss: 0.1125 - val_accuracy: 0.9734\n",
      "Epoch 67/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1371 - accuracy: 0.9580 - val_loss: 0.1115 - val_accuracy: 0.9734\n",
      "Epoch 68/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1358 - accuracy: 0.9580 - val_loss: 0.1106 - val_accuracy: 0.9734\n",
      "Epoch 69/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1347 - accuracy: 0.9580 - val_loss: 0.1097 - val_accuracy: 0.9734\n",
      "Epoch 70/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1336 - accuracy: 0.9606 - val_loss: 0.1088 - val_accuracy: 0.9734\n",
      "Epoch 71/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.1324 - accuracy: 0.9606 - val_loss: 0.1080 - val_accuracy: 0.9734\n",
      "Epoch 72/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1314 - accuracy: 0.9606 - val_loss: 0.1072 - val_accuracy: 0.9734\n",
      "Epoch 73/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1303 - accuracy: 0.9606 - val_loss: 0.1064 - val_accuracy: 0.9734\n",
      "Epoch 74/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1293 - accuracy: 0.9606 - val_loss: 0.1056 - val_accuracy: 0.9734\n",
      "Epoch 75/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.1282 - accuracy: 0.9606 - val_loss: 0.1049 - val_accuracy: 0.9734\n",
      "Epoch 76/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1273 - accuracy: 0.9606 - val_loss: 0.1041 - val_accuracy: 0.9734\n",
      "Epoch 77/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1263 - accuracy: 0.9606 - val_loss: 0.1034 - val_accuracy: 0.9734\n",
      "Epoch 78/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1254 - accuracy: 0.9606 - val_loss: 0.1027 - val_accuracy: 0.9734\n",
      "Epoch 79/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.1244 - accuracy: 0.9606 - val_loss: 0.1020 - val_accuracy: 0.9734\n",
      "Epoch 80/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.1235 - accuracy: 0.9606 - val_loss: 0.1013 - val_accuracy: 0.9734\n",
      "Epoch 81/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1226 - accuracy: 0.9606 - val_loss: 0.1007 - val_accuracy: 0.9734\n",
      "Epoch 82/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1218 - accuracy: 0.9659 - val_loss: 0.1000 - val_accuracy: 0.9734\n",
      "Epoch 83/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1209 - accuracy: 0.9659 - val_loss: 0.0995 - val_accuracy: 0.9734\n",
      "Epoch 84/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1201 - accuracy: 0.9659 - val_loss: 0.0988 - val_accuracy: 0.9734\n",
      "Epoch 85/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1192 - accuracy: 0.9659 - val_loss: 0.0983 - val_accuracy: 0.9734\n",
      "Epoch 86/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.1185 - accuracy: 0.9659 - val_loss: 0.0977 - val_accuracy: 0.9734\n",
      "Epoch 87/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.1177 - accuracy: 0.9659 - val_loss: 0.0971 - val_accuracy: 0.9734\n",
      "Epoch 88/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1169 - accuracy: 0.9659 - val_loss: 0.0965 - val_accuracy: 0.9734\n",
      "Epoch 89/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1161 - accuracy: 0.9659 - val_loss: 0.0960 - val_accuracy: 0.9734\n",
      "Epoch 90/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1154 - accuracy: 0.9659 - val_loss: 0.0955 - val_accuracy: 0.9734\n",
      "Epoch 91/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.1147 - accuracy: 0.9659 - val_loss: 0.0949 - val_accuracy: 0.9734\n",
      "Epoch 92/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1140 - accuracy: 0.9685 - val_loss: 0.0944 - val_accuracy: 0.9734\n",
      "Epoch 93/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1132 - accuracy: 0.9685 - val_loss: 0.0939 - val_accuracy: 0.9734\n",
      "Epoch 94/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1126 - accuracy: 0.9685 - val_loss: 0.0934 - val_accuracy: 0.9734\n",
      "Epoch 95/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1119 - accuracy: 0.9685 - val_loss: 0.0930 - val_accuracy: 0.9734\n",
      "Epoch 96/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.1113 - accuracy: 0.9685 - val_loss: 0.0926 - val_accuracy: 0.9734\n",
      "Epoch 97/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.1106 - accuracy: 0.9685 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
      "Epoch 98/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1100 - accuracy: 0.9685 - val_loss: 0.0916 - val_accuracy: 0.9734\n",
      "Epoch 99/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1093 - accuracy: 0.9685 - val_loss: 0.0911 - val_accuracy: 0.9734\n",
      "Epoch 100/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.1087 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9734\n",
      "Epoch 101/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.1081 - accuracy: 0.9685 - val_loss: 0.0903 - val_accuracy: 0.9734\n",
      "Epoch 102/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.1075 - accuracy: 0.9685 - val_loss: 0.0899 - val_accuracy: 0.9734\n",
      "Epoch 103/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1069 - accuracy: 0.9685 - val_loss: 0.0895 - val_accuracy: 0.9734\n",
      "Epoch 104/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1063 - accuracy: 0.9685 - val_loss: 0.0891 - val_accuracy: 0.9734\n",
      "Epoch 105/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1057 - accuracy: 0.9685 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
      "Epoch 106/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1052 - accuracy: 0.9685 - val_loss: 0.0883 - val_accuracy: 0.9734\n",
      "Epoch 107/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1046 - accuracy: 0.9685 - val_loss: 0.0878 - val_accuracy: 0.9734\n",
      "Epoch 108/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1041 - accuracy: 0.9685 - val_loss: 0.0875 - val_accuracy: 0.9787\n",
      "Epoch 109/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1035 - accuracy: 0.9685 - val_loss: 0.0871 - val_accuracy: 0.9787\n",
      "Epoch 110/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.1031 - accuracy: 0.9685 - val_loss: 0.0868 - val_accuracy: 0.9787\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 107us/sample - loss: 0.1025 - accuracy: 0.9711 - val_loss: 0.0865 - val_accuracy: 0.9787\n",
      "Epoch 112/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.1020 - accuracy: 0.9711 - val_loss: 0.0861 - val_accuracy: 0.9787\n",
      "Epoch 113/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.1015 - accuracy: 0.9711 - val_loss: 0.0857 - val_accuracy: 0.9787\n",
      "Epoch 114/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1011 - accuracy: 0.9711 - val_loss: 0.0854 - val_accuracy: 0.9787\n",
      "Epoch 115/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.1005 - accuracy: 0.9711 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
      "Epoch 116/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1001 - accuracy: 0.9711 - val_loss: 0.0848 - val_accuracy: 0.9787\n",
      "Epoch 117/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0996 - accuracy: 0.9711 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
      "Epoch 118/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0991 - accuracy: 0.9711 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
      "Epoch 119/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0987 - accuracy: 0.9711 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
      "Epoch 120/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.0982 - accuracy: 0.9711 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
      "Epoch 121/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0978 - accuracy: 0.9711 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
      "Epoch 122/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0974 - accuracy: 0.9738 - val_loss: 0.0829 - val_accuracy: 0.9787\n",
      "Epoch 123/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0970 - accuracy: 0.9738 - val_loss: 0.0826 - val_accuracy: 0.9787\n",
      "Epoch 124/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0965 - accuracy: 0.9764 - val_loss: 0.0823 - val_accuracy: 0.9787\n",
      "Epoch 125/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0961 - accuracy: 0.9738 - val_loss: 0.0821 - val_accuracy: 0.9787\n",
      "Epoch 126/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0957 - accuracy: 0.9764 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
      "Epoch 127/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0954 - accuracy: 0.9764 - val_loss: 0.0815 - val_accuracy: 0.9787\n",
      "Epoch 128/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0949 - accuracy: 0.9764 - val_loss: 0.0812 - val_accuracy: 0.9787\n",
      "Epoch 129/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0945 - accuracy: 0.9764 - val_loss: 0.0809 - val_accuracy: 0.9787\n",
      "Epoch 130/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0941 - accuracy: 0.9790 - val_loss: 0.0807 - val_accuracy: 0.9787\n",
      "Epoch 131/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0804 - val_accuracy: 0.9787\n",
      "Epoch 132/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0802 - val_accuracy: 0.9787\n",
      "Epoch 133/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0929 - accuracy: 0.9790 - val_loss: 0.0799 - val_accuracy: 0.9787\n",
      "Epoch 134/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0926 - accuracy: 0.9790 - val_loss: 0.0797 - val_accuracy: 0.9787\n",
      "Epoch 135/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0922 - accuracy: 0.9790 - val_loss: 0.0794 - val_accuracy: 0.9787\n",
      "Epoch 136/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0919 - accuracy: 0.9790 - val_loss: 0.0792 - val_accuracy: 0.9787\n",
      "Epoch 137/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0915 - accuracy: 0.9790 - val_loss: 0.0789 - val_accuracy: 0.9787\n",
      "Epoch 138/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0911 - accuracy: 0.9816 - val_loss: 0.0787 - val_accuracy: 0.9787\n",
      "Epoch 139/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0908 - accuracy: 0.9816 - val_loss: 0.0785 - val_accuracy: 0.9787\n",
      "Epoch 140/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0905 - accuracy: 0.9816 - val_loss: 0.0782 - val_accuracy: 0.9787\n",
      "Epoch 141/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0901 - accuracy: 0.9816 - val_loss: 0.0780 - val_accuracy: 0.9787\n",
      "Epoch 142/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0898 - accuracy: 0.9816 - val_loss: 0.0778 - val_accuracy: 0.9787\n",
      "Epoch 143/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0895 - accuracy: 0.9816 - val_loss: 0.0775 - val_accuracy: 0.9787\n",
      "Epoch 144/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0891 - accuracy: 0.9816 - val_loss: 0.0773 - val_accuracy: 0.9787\n",
      "Epoch 145/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0888 - accuracy: 0.9816 - val_loss: 0.0771 - val_accuracy: 0.9787\n",
      "Epoch 146/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0885 - accuracy: 0.9816 - val_loss: 0.0769 - val_accuracy: 0.9787\n",
      "Epoch 147/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0882 - accuracy: 0.9816 - val_loss: 0.0767 - val_accuracy: 0.9787\n",
      "Epoch 148/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0879 - accuracy: 0.9816 - val_loss: 0.0765 - val_accuracy: 0.9787\n",
      "Epoch 149/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0876 - accuracy: 0.9816 - val_loss: 0.0763 - val_accuracy: 0.9787\n",
      "Epoch 150/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0873 - accuracy: 0.9816 - val_loss: 0.0761 - val_accuracy: 0.9787\n",
      "Epoch 151/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0870 - accuracy: 0.9816 - val_loss: 0.0759 - val_accuracy: 0.9787\n",
      "Epoch 152/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0867 - accuracy: 0.9843 - val_loss: 0.0757 - val_accuracy: 0.9787\n",
      "Epoch 153/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0864 - accuracy: 0.9843 - val_loss: 0.0755 - val_accuracy: 0.9787\n",
      "Epoch 154/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0861 - accuracy: 0.9843 - val_loss: 0.0753 - val_accuracy: 0.9787\n",
      "Epoch 155/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0858 - accuracy: 0.9843 - val_loss: 0.0751 - val_accuracy: 0.9787\n",
      "Epoch 156/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0855 - accuracy: 0.9843 - val_loss: 0.0749 - val_accuracy: 0.9787\n",
      "Epoch 157/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0852 - accuracy: 0.9843 - val_loss: 0.0747 - val_accuracy: 0.9787\n",
      "Epoch 158/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0850 - accuracy: 0.9843 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
      "Epoch 159/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0847 - accuracy: 0.9843 - val_loss: 0.0744 - val_accuracy: 0.9787\n",
      "Epoch 160/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0844 - accuracy: 0.9869 - val_loss: 0.0742 - val_accuracy: 0.9787\n",
      "Epoch 161/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0842 - accuracy: 0.9869 - val_loss: 0.0740 - val_accuracy: 0.9787\n",
      "Epoch 162/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0839 - accuracy: 0.9869 - val_loss: 0.0738 - val_accuracy: 0.9787\n",
      "Epoch 163/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0836 - accuracy: 0.9869 - val_loss: 0.0737 - val_accuracy: 0.9787\n",
      "Epoch 164/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0834 - accuracy: 0.9869 - val_loss: 0.0735 - val_accuracy: 0.9787\n",
      "Epoch 165/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0831 - accuracy: 0.9869 - val_loss: 0.0733 - val_accuracy: 0.9787\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0829 - accuracy: 0.9869 - val_loss: 0.0731 - val_accuracy: 0.9787\n",
      "Epoch 167/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0826 - accuracy: 0.9869 - val_loss: 0.0730 - val_accuracy: 0.9787\n",
      "Epoch 168/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0824 - accuracy: 0.9869 - val_loss: 0.0728 - val_accuracy: 0.9787\n",
      "Epoch 169/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0822 - accuracy: 0.9869 - val_loss: 0.0727 - val_accuracy: 0.9787\n",
      "Epoch 170/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0819 - accuracy: 0.9869 - val_loss: 0.0725 - val_accuracy: 0.9787\n",
      "Epoch 171/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0817 - accuracy: 0.9869 - val_loss: 0.0723 - val_accuracy: 0.9787\n",
      "Epoch 172/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0814 - accuracy: 0.9869 - val_loss: 0.0722 - val_accuracy: 0.9787\n",
      "Epoch 173/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0812 - accuracy: 0.9869 - val_loss: 0.0720 - val_accuracy: 0.9787\n",
      "Epoch 174/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0810 - accuracy: 0.9869 - val_loss: 0.0718 - val_accuracy: 0.9787\n",
      "Epoch 175/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0807 - accuracy: 0.9869 - val_loss: 0.0716 - val_accuracy: 0.9787\n",
      "Epoch 176/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0805 - accuracy: 0.9869 - val_loss: 0.0715 - val_accuracy: 0.9787\n",
      "Epoch 177/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0803 - accuracy: 0.9869 - val_loss: 0.0714 - val_accuracy: 0.9787\n",
      "Epoch 178/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0800 - accuracy: 0.9869 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
      "Epoch 179/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0798 - accuracy: 0.9869 - val_loss: 0.0711 - val_accuracy: 0.9787\n",
      "Epoch 180/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0796 - accuracy: 0.9869 - val_loss: 0.0710 - val_accuracy: 0.9787\n",
      "Epoch 181/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0794 - accuracy: 0.9869 - val_loss: 0.0708 - val_accuracy: 0.9787\n",
      "Epoch 182/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0792 - accuracy: 0.9869 - val_loss: 0.0706 - val_accuracy: 0.9787\n",
      "Epoch 183/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0790 - accuracy: 0.9869 - val_loss: 0.0706 - val_accuracy: 0.9787\n",
      "Epoch 184/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0787 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9787\n",
      "Epoch 185/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0785 - accuracy: 0.9869 - val_loss: 0.0703 - val_accuracy: 0.9787\n",
      "Epoch 186/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0784 - accuracy: 0.9869 - val_loss: 0.0701 - val_accuracy: 0.9787\n",
      "Epoch 187/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0781 - accuracy: 0.9869 - val_loss: 0.0700 - val_accuracy: 0.9787\n",
      "Epoch 188/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0779 - accuracy: 0.9869 - val_loss: 0.0699 - val_accuracy: 0.9787\n",
      "Epoch 189/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0777 - accuracy: 0.9869 - val_loss: 0.0698 - val_accuracy: 0.9787\n",
      "Epoch 190/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0775 - accuracy: 0.9869 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
      "Epoch 191/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0773 - accuracy: 0.9869 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
      "Epoch 192/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0772 - accuracy: 0.9869 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
      "Epoch 193/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0769 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
      "Epoch 194/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0768 - accuracy: 0.9869 - val_loss: 0.0691 - val_accuracy: 0.9787\n",
      "Epoch 195/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.0766 - accuracy: 0.9869 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
      "Epoch 196/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0764 - accuracy: 0.9869 - val_loss: 0.0688 - val_accuracy: 0.9787\n",
      "Epoch 197/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0762 - accuracy: 0.9869 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
      "Epoch 198/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
      "Epoch 199/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0758 - accuracy: 0.9869 - val_loss: 0.0685 - val_accuracy: 0.9787\n",
      "Epoch 200/500\n",
      "381/381 [==============================] - 0s 104us/sample - loss: 0.0757 - accuracy: 0.9869 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
      "Epoch 201/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0755 - accuracy: 0.9869 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
      "Epoch 202/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.0753 - accuracy: 0.9869 - val_loss: 0.0682 - val_accuracy: 0.9787\n",
      "Epoch 203/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0751 - accuracy: 0.9869 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
      "Epoch 204/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0749 - accuracy: 0.9869 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
      "Epoch 205/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0748 - accuracy: 0.9869 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
      "Epoch 206/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0746 - accuracy: 0.9869 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
      "Epoch 207/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0744 - accuracy: 0.9869 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
      "Epoch 208/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0743 - accuracy: 0.9869 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
      "Epoch 209/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0741 - accuracy: 0.9869 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
      "Epoch 210/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0739 - accuracy: 0.9869 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
      "Epoch 211/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0738 - accuracy: 0.9869 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
      "Epoch 212/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0736 - accuracy: 0.9869 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
      "Epoch 213/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0734 - accuracy: 0.9869 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
      "Epoch 214/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0733 - accuracy: 0.9869 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
      "Epoch 215/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0731 - accuracy: 0.9869 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
      "Epoch 216/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0730 - accuracy: 0.9869 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
      "Epoch 217/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.0729 - accuracy: 0.9869 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
      "Epoch 218/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0727 - accuracy: 0.9869 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
      "Epoch 219/500\n",
      "381/381 [==============================] - 0s 106us/sample - loss: 0.0726 - accuracy: 0.9869 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
      "Epoch 220/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0724 - accuracy: 0.9869 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0722 - accuracy: 0.9869 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
      "Epoch 222/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0721 - accuracy: 0.9869 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
      "Epoch 223/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0719 - accuracy: 0.9869 - val_loss: 0.0660 - val_accuracy: 0.9787\n",
      "Epoch 224/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
      "Epoch 225/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0717 - accuracy: 0.9869 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
      "Epoch 226/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0715 - accuracy: 0.9869 - val_loss: 0.0656 - val_accuracy: 0.9787\n",
      "Epoch 227/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0714 - accuracy: 0.9869 - val_loss: 0.0656 - val_accuracy: 0.9787\n",
      "Epoch 228/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0654 - val_accuracy: 0.9787\n",
      "Epoch 229/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0711 - accuracy: 0.9869 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 230/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 231/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0708 - accuracy: 0.9869 - val_loss: 0.0652 - val_accuracy: 0.9787\n",
      "Epoch 232/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0706 - accuracy: 0.9869 - val_loss: 0.0651 - val_accuracy: 0.9787\n",
      "Epoch 233/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0705 - accuracy: 0.9869 - val_loss: 0.0650 - val_accuracy: 0.9787\n",
      "Epoch 234/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0704 - accuracy: 0.9869 - val_loss: 0.0649 - val_accuracy: 0.9787\n",
      "Epoch 235/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0702 - accuracy: 0.9869 - val_loss: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 236/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0701 - accuracy: 0.9869 - val_loss: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 237/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0700 - accuracy: 0.9869 - val_loss: 0.0647 - val_accuracy: 0.9787\n",
      "Epoch 238/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0698 - accuracy: 0.9869 - val_loss: 0.0645 - val_accuracy: 0.9787\n",
      "Epoch 239/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0697 - accuracy: 0.9869 - val_loss: 0.0645 - val_accuracy: 0.9840\n",
      "Epoch 240/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0696 - accuracy: 0.9869 - val_loss: 0.0644 - val_accuracy: 0.9840\n",
      "Epoch 241/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0695 - accuracy: 0.9869 - val_loss: 0.0643 - val_accuracy: 0.9840\n",
      "Epoch 242/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0693 - accuracy: 0.9869 - val_loss: 0.0642 - val_accuracy: 0.9787\n",
      "Epoch 243/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0692 - accuracy: 0.9869 - val_loss: 0.0641 - val_accuracy: 0.9840\n",
      "Epoch 244/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0691 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
      "Epoch 245/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0689 - accuracy: 0.9869 - val_loss: 0.0639 - val_accuracy: 0.9840\n",
      "Epoch 246/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0688 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
      "Epoch 247/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0687 - accuracy: 0.9869 - val_loss: 0.0638 - val_accuracy: 0.9840\n",
      "Epoch 248/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0686 - accuracy: 0.9869 - val_loss: 0.0638 - val_accuracy: 0.9840\n",
      "Epoch 249/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0685 - accuracy: 0.9869 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
      "Epoch 250/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0683 - accuracy: 0.9869 - val_loss: 0.0636 - val_accuracy: 0.9840\n",
      "Epoch 251/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0682 - accuracy: 0.9869 - val_loss: 0.0635 - val_accuracy: 0.9840\n",
      "Epoch 252/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0681 - accuracy: 0.9869 - val_loss: 0.0634 - val_accuracy: 0.9840\n",
      "Epoch 253/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0680 - accuracy: 0.9869 - val_loss: 0.0634 - val_accuracy: 0.9840\n",
      "Epoch 254/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0679 - accuracy: 0.9869 - val_loss: 0.0634 - val_accuracy: 0.9840\n",
      "Epoch 255/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0678 - accuracy: 0.9869 - val_loss: 0.0632 - val_accuracy: 0.9840\n",
      "Epoch 256/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0676 - accuracy: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9840\n",
      "Epoch 257/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0676 - accuracy: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9840\n",
      "Epoch 258/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0674 - accuracy: 0.9869 - val_loss: 0.0630 - val_accuracy: 0.9840\n",
      "Epoch 259/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0673 - accuracy: 0.9869 - val_loss: 0.0629 - val_accuracy: 0.9840\n",
      "Epoch 260/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0673 - accuracy: 0.9869 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
      "Epoch 261/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0671 - accuracy: 0.9869 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
      "Epoch 262/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0670 - accuracy: 0.9869 - val_loss: 0.0627 - val_accuracy: 0.9840\n",
      "Epoch 263/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0669 - accuracy: 0.9869 - val_loss: 0.0627 - val_accuracy: 0.9840\n",
      "Epoch 264/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0668 - accuracy: 0.9869 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
      "Epoch 265/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0667 - accuracy: 0.9869 - val_loss: 0.0625 - val_accuracy: 0.9840\n",
      "Epoch 266/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.0625 - val_accuracy: 0.9840\n",
      "Epoch 267/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0665 - accuracy: 0.9869 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
      "Epoch 268/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0663 - accuracy: 0.9869 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
      "Epoch 269/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.0623 - val_accuracy: 0.9840\n",
      "Epoch 270/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
      "Epoch 271/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
      "Epoch 272/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0621 - val_accuracy: 0.9840\n",
      "Epoch 273/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.0620 - val_accuracy: 0.9840\n",
      "Epoch 274/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.0620 - val_accuracy: 0.9840\n",
      "Epoch 275/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0656 - accuracy: 0.9869 - val_loss: 0.0619 - val_accuracy: 0.9840\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.0618 - val_accuracy: 0.9840\n",
      "Epoch 277/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.0618 - val_accuracy: 0.9840\n",
      "Epoch 278/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.0617 - val_accuracy: 0.9840\n",
      "Epoch 279/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
      "Epoch 280/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
      "Epoch 281/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0651 - accuracy: 0.9869 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
      "Epoch 282/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 283/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 284/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
      "Epoch 285/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0647 - accuracy: 0.9869 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
      "Epoch 286/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0646 - accuracy: 0.9869 - val_loss: 0.0612 - val_accuracy: 0.9894\n",
      "Epoch 287/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0645 - accuracy: 0.9869 - val_loss: 0.0612 - val_accuracy: 0.9840\n",
      "Epoch 288/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0644 - accuracy: 0.9869 - val_loss: 0.0611 - val_accuracy: 0.9840\n",
      "Epoch 289/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 290/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0642 - accuracy: 0.9869 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 291/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 292/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
      "Epoch 293/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.0608 - val_accuracy: 0.9894\n",
      "Epoch 294/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.0608 - val_accuracy: 0.9894\n",
      "Epoch 295/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0638 - accuracy: 0.9869 - val_loss: 0.0608 - val_accuracy: 0.9840\n",
      "Epoch 296/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0637 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9894\n",
      "Epoch 297/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9894\n",
      "Epoch 298/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.0606 - val_accuracy: 0.9894\n",
      "Epoch 299/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.0606 - val_accuracy: 0.9894\n",
      "Epoch 300/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0605 - val_accuracy: 0.9894\n",
      "Epoch 301/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0633 - accuracy: 0.9869 - val_loss: 0.0604 - val_accuracy: 0.9894\n",
      "Epoch 302/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0633 - accuracy: 0.9869 - val_loss: 0.0604 - val_accuracy: 0.9894\n",
      "Epoch 303/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.0603 - val_accuracy: 0.9894\n",
      "Epoch 304/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0603 - val_accuracy: 0.9894\n",
      "Epoch 305/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0602 - val_accuracy: 0.9894\n",
      "Epoch 306/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.0602 - val_accuracy: 0.9894\n",
      "Epoch 307/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.0601 - val_accuracy: 0.9894\n",
      "Epoch 308/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.0601 - val_accuracy: 0.9894\n",
      "Epoch 309/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0626 - accuracy: 0.9869 - val_loss: 0.0601 - val_accuracy: 0.9894\n",
      "Epoch 310/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0600 - val_accuracy: 0.9894\n",
      "Epoch 311/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0600 - val_accuracy: 0.9894\n",
      "Epoch 312/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0624 - accuracy: 0.9869 - val_loss: 0.0600 - val_accuracy: 0.9894\n",
      "Epoch 313/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9894\n",
      "Epoch 314/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9894\n",
      "Epoch 315/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0598 - val_accuracy: 0.9894\n",
      "Epoch 316/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0621 - accuracy: 0.9869 - val_loss: 0.0597 - val_accuracy: 0.9894\n",
      "Epoch 317/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9894\n",
      "Epoch 318/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0597 - val_accuracy: 0.9894\n",
      "Epoch 319/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9894\n",
      "Epoch 320/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9894\n",
      "Epoch 321/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.0595 - val_accuracy: 0.9894\n",
      "Epoch 322/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0595 - val_accuracy: 0.9894\n",
      "Epoch 323/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0594 - val_accuracy: 0.9894\n",
      "Epoch 324/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0615 - accuracy: 0.9869 - val_loss: 0.0594 - val_accuracy: 0.9894\n",
      "Epoch 325/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9894\n",
      "Epoch 326/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9894\n",
      "Epoch 327/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0613 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9894\n",
      "Epoch 328/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9894\n",
      "Epoch 329/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0591 - val_accuracy: 0.9894\n",
      "Epoch 330/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.0591 - val_accuracy: 0.9894\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0610 - accuracy: 0.9869 - val_loss: 0.0591 - val_accuracy: 0.9894\n",
      "Epoch 332/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0590 - val_accuracy: 0.9894\n",
      "Epoch 333/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0590 - val_accuracy: 0.9894\n",
      "Epoch 334/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0608 - accuracy: 0.9869 - val_loss: 0.0589 - val_accuracy: 0.9894\n",
      "Epoch 335/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0589 - val_accuracy: 0.9894\n",
      "Epoch 336/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0589 - val_accuracy: 0.9894\n",
      "Epoch 337/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.0588 - val_accuracy: 0.9894\n",
      "Epoch 338/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0588 - val_accuracy: 0.9894\n",
      "Epoch 339/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0588 - val_accuracy: 0.9894\n",
      "Epoch 340/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0604 - accuracy: 0.9869 - val_loss: 0.0587 - val_accuracy: 0.9894\n",
      "Epoch 341/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0588 - val_accuracy: 0.9894\n",
      "Epoch 342/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0587 - val_accuracy: 0.9894\n",
      "Epoch 343/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0587 - val_accuracy: 0.9894\n",
      "Epoch 344/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.0586 - val_accuracy: 0.9894\n",
      "Epoch 345/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.0586 - val_accuracy: 0.9894\n",
      "Epoch 346/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9894\n",
      "Epoch 347/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9894\n",
      "Epoch 348/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9894\n",
      "Epoch 349/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0584 - val_accuracy: 0.9894\n",
      "Epoch 350/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0584 - val_accuracy: 0.9894\n",
      "Epoch 351/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.0584 - val_accuracy: 0.9894\n",
      "Epoch 352/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0583 - val_accuracy: 0.9894\n",
      "Epoch 353/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0583 - val_accuracy: 0.9894\n",
      "Epoch 354/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0583 - val_accuracy: 0.9894\n",
      "Epoch 355/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0582 - val_accuracy: 0.9894\n",
      "Epoch 356/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0582 - val_accuracy: 0.9894\n",
      "Epoch 357/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0581 - val_accuracy: 0.9894\n",
      "Epoch 358/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0582 - val_accuracy: 0.9894\n",
      "Epoch 359/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.0581 - val_accuracy: 0.9894\n",
      "Epoch 360/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.0581 - val_accuracy: 0.9894\n",
      "Epoch 361/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0580 - val_accuracy: 0.9894\n",
      "Epoch 362/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0580 - val_accuracy: 0.9894\n",
      "Epoch 363/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0590 - accuracy: 0.9869 - val_loss: 0.0580 - val_accuracy: 0.9894\n",
      "Epoch 364/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0579 - val_accuracy: 0.9894\n",
      "Epoch 365/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0579 - val_accuracy: 0.9894\n",
      "Epoch 366/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0578 - val_accuracy: 0.9894\n",
      "Epoch 367/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0579 - val_accuracy: 0.9894\n",
      "Epoch 368/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0578 - val_accuracy: 0.9894\n",
      "Epoch 369/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0578 - val_accuracy: 0.9894\n",
      "Epoch 370/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 0.9894\n",
      "Epoch 371/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 0.9894\n",
      "Epoch 372/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 0.9894\n",
      "Epoch 373/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 0.9894\n",
      "Epoch 374/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0576 - val_accuracy: 0.9894\n",
      "Epoch 375/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0576 - val_accuracy: 0.9894\n",
      "Epoch 376/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0583 - accuracy: 0.9895 - val_loss: 0.0576 - val_accuracy: 0.9894\n",
      "Epoch 377/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0575 - val_accuracy: 0.9894\n",
      "Epoch 378/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.0575 - val_accuracy: 0.9894\n",
      "Epoch 379/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0574 - val_accuracy: 0.9894\n",
      "Epoch 380/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0581 - accuracy: 0.9895 - val_loss: 0.0575 - val_accuracy: 0.9894\n",
      "Epoch 381/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0574 - val_accuracy: 0.9894\n",
      "Epoch 382/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0574 - val_accuracy: 0.9894\n",
      "Epoch 383/500\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0574 - val_accuracy: 0.9894\n",
      "Epoch 384/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0574 - val_accuracy: 0.9894\n",
      "Epoch 385/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0573 - val_accuracy: 0.9894\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 387/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 388/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 389/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0576 - accuracy: 0.9895 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 390/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0575 - accuracy: 0.9895 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 391/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0575 - accuracy: 0.9895 - val_loss: 0.0572 - val_accuracy: 0.9894\n",
      "Epoch 392/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0575 - accuracy: 0.9895 - val_loss: 0.0571 - val_accuracy: 0.9894\n",
      "Epoch 393/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0574 - accuracy: 0.9895 - val_loss: 0.0571 - val_accuracy: 0.9894\n",
      "Epoch 394/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0574 - accuracy: 0.9895 - val_loss: 0.0571 - val_accuracy: 0.9894\n",
      "Epoch 395/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0573 - accuracy: 0.9895 - val_loss: 0.0570 - val_accuracy: 0.9894\n",
      "Epoch 396/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0573 - accuracy: 0.9895 - val_loss: 0.0570 - val_accuracy: 0.9894\n",
      "Epoch 397/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0570 - val_accuracy: 0.9894\n",
      "Epoch 398/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0570 - val_accuracy: 0.9894\n",
      "Epoch 399/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0571 - accuracy: 0.9869 - val_loss: 0.0569 - val_accuracy: 0.9894\n",
      "Epoch 400/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0571 - accuracy: 0.9869 - val_loss: 0.0569 - val_accuracy: 0.9894\n",
      "Epoch 401/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0571 - accuracy: 0.9869 - val_loss: 0.0569 - val_accuracy: 0.9894\n",
      "Epoch 402/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0570 - accuracy: 0.9895 - val_loss: 0.0569 - val_accuracy: 0.9894\n",
      "Epoch 403/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0570 - accuracy: 0.9895 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 404/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0569 - accuracy: 0.9869 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 405/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0568 - accuracy: 0.9895 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 406/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0568 - accuracy: 0.9895 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 407/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 408/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0567 - val_accuracy: 0.9894\n",
      "Epoch 409/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
      "Epoch 410/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0566 - accuracy: 0.9895 - val_loss: 0.0567 - val_accuracy: 0.9894\n",
      "Epoch 411/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0566 - accuracy: 0.9895 - val_loss: 0.0567 - val_accuracy: 0.9894\n",
      "Epoch 412/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0566 - accuracy: 0.9895 - val_loss: 0.0566 - val_accuracy: 0.9894\n",
      "Epoch 413/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0565 - accuracy: 0.9895 - val_loss: 0.0566 - val_accuracy: 0.9894\n",
      "Epoch 414/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0564 - accuracy: 0.9869 - val_loss: 0.0566 - val_accuracy: 0.9894\n",
      "Epoch 415/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0564 - accuracy: 0.9869 - val_loss: 0.0566 - val_accuracy: 0.9894\n",
      "Epoch 416/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0564 - accuracy: 0.9895 - val_loss: 0.0566 - val_accuracy: 0.9894\n",
      "Epoch 417/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0563 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 418/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0563 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 419/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0562 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 420/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0562 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 421/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 422/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 423/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0564 - val_accuracy: 0.9894\n",
      "Epoch 424/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0560 - accuracy: 0.9895 - val_loss: 0.0564 - val_accuracy: 0.9894\n",
      "Epoch 425/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0560 - accuracy: 0.9895 - val_loss: 0.0564 - val_accuracy: 0.9894\n",
      "Epoch 426/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0560 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 427/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0559 - accuracy: 0.9895 - val_loss: 0.0564 - val_accuracy: 0.9894\n",
      "Epoch 428/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0559 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 429/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0559 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 430/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0558 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 431/500\n",
      "381/381 [==============================] - 0s 144us/sample - loss: 0.0558 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 432/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.0557 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 433/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0557 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9894\n",
      "Epoch 434/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 435/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 436/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 437/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0555 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 438/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0555 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 439/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0554 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 440/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0554 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0554 - accuracy: 0.9895 - val_loss: 0.0562 - val_accuracy: 0.9894\n",
      "Epoch 442/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0554 - accuracy: 0.9895 - val_loss: 0.0561 - val_accuracy: 0.9894\n",
      "Epoch 443/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0553 - accuracy: 0.9895 - val_loss: 0.0561 - val_accuracy: 0.9894\n",
      "Epoch 444/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0553 - accuracy: 0.9895 - val_loss: 0.0561 - val_accuracy: 0.9894\n",
      "Epoch 445/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0552 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 446/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0552 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 447/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0551 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 448/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0551 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 449/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0551 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 450/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0550 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 451/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0550 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9894\n",
      "Epoch 452/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0550 - accuracy: 0.9895 - val_loss: 0.0559 - val_accuracy: 0.9894\n",
      "Epoch 453/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0549 - accuracy: 0.9895 - val_loss: 0.0559 - val_accuracy: 0.9894\n",
      "Epoch 454/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0549 - accuracy: 0.9895 - val_loss: 0.0559 - val_accuracy: 0.9894\n",
      "Epoch 455/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0549 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 456/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0548 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 457/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0548 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 458/500\n",
      "381/381 [==============================] - 0s 103us/sample - loss: 0.0547 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 459/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0547 - accuracy: 0.9895 - val_loss: 0.0559 - val_accuracy: 0.9894\n",
      "Epoch 460/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0547 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 461/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0547 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 462/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0546 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 463/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0546 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 464/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0546 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9894\n",
      "Epoch 465/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0545 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 466/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0545 - accuracy: 0.9869 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 467/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0544 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 468/500\n",
      "381/381 [==============================] - 0s 109us/sample - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 469/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0544 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 470/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0543 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 471/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0543 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 472/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0543 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
      "Epoch 473/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0542 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 474/500\n",
      "381/381 [==============================] - 0s 108us/sample - loss: 0.0542 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 475/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0542 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 476/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0542 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 477/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0541 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 478/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0541 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 479/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0541 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
      "Epoch 480/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 481/500\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 482/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 483/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 484/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 485/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 486/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 487/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0538 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 488/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0538 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 489/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0538 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 490/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0537 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 491/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0537 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 492/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0537 - accuracy: 0.9895 - val_loss: 0.0554 - val_accuracy: 0.9894\n",
      "Epoch 493/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0536 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 494/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0536 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 495/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0536 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0535 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 497/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0535 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 498/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0535 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 499/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0535 - accuracy: 0.9895 - val_loss: 0.0552 - val_accuracy: 0.9894\n",
      "Epoch 500/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0535 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "381/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 45us/sample - loss: 0.0717 - accuracy: 0.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: [0.05336851798721499, 0.9895013]\n",
      "188/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 56us/sample - loss: 0.0398 - accuracy: 0.9894\n",
      "Test score: [0.05531288283143906, 0.9893617]\n"
     ]
    }
   ],
   "source": [
    "# Now all the fun Tensorflow stuff\n",
    "# Build the model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Alternatively, you can do:\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n",
    "\n",
    "# Evalute the model - evaluate() returns loass and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff740e38198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot what's returned by model.fit()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff740915128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy too\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00]\n",
      " [9.9999917e-01]\n",
      " [1.7881393e-07]\n",
      " [3.6525995e-02]\n",
      " [9.9988878e-01]\n",
      " [9.9984515e-01]\n",
      " [9.8787963e-01]\n",
      " [9.7526121e-01]\n",
      " [6.2584877e-07]\n",
      " [9.6539676e-01]\n",
      " [6.9772565e-01]\n",
      " [2.7333498e-03]\n",
      " [9.9481207e-01]\n",
      " [9.9999559e-01]\n",
      " [9.9947548e-01]\n",
      " [1.6987324e-06]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [9.9999726e-01]\n",
      " [9.9991286e-01]\n",
      " [9.9998951e-01]\n",
      " [9.9440372e-01]\n",
      " [7.6265603e-02]\n",
      " [9.9907959e-01]\n",
      " [9.4322473e-01]\n",
      " [9.9916905e-01]\n",
      " [9.9958432e-01]\n",
      " [1.4901161e-07]\n",
      " [1.3639331e-03]\n",
      " [9.9999905e-01]\n",
      " [5.9604645e-08]\n",
      " [9.9922824e-01]\n",
      " [5.4299831e-05]\n",
      " [6.1298925e-01]\n",
      " [1.4901161e-06]\n",
      " [5.2551001e-01]\n",
      " [9.3884826e-01]\n",
      " [8.9388072e-01]\n",
      " [9.6900016e-01]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [2.1338463e-05]\n",
      " [9.9999881e-01]\n",
      " [2.9802322e-08]\n",
      " [9.9991727e-01]\n",
      " [8.6128712e-06]\n",
      " [9.9150550e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9989104e-01]\n",
      " [9.9971211e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9998957e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9401593e-01]\n",
      " [0.0000000e+00]\n",
      " [8.1055284e-01]\n",
      " [9.9998796e-01]\n",
      " [9.9975729e-01]\n",
      " [9.9972147e-01]\n",
      " [9.9103415e-01]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [9.9993831e-01]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [2.9802322e-08]\n",
      " [9.8176503e-01]\n",
      " [0.0000000e+00]\n",
      " [3.0100346e-06]\n",
      " [1.7881393e-07]\n",
      " [2.0725429e-03]\n",
      " [8.4057629e-01]\n",
      " [9.9970174e-01]\n",
      " [9.9997151e-01]\n",
      " [4.1849554e-02]\n",
      " [9.3220341e-01]\n",
      " [9.9193287e-01]\n",
      " [8.5444808e-01]\n",
      " [9.9871147e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9999839e-01]\n",
      " [9.9999857e-01]\n",
      " [9.9982816e-01]\n",
      " [0.0000000e+00]\n",
      " [5.8412552e-06]\n",
      " [9.9996185e-01]\n",
      " [4.2688030e-01]\n",
      " [9.9991083e-01]\n",
      " [9.9942398e-01]\n",
      " [7.3486567e-04]\n",
      " [2.6753372e-01]\n",
      " [9.9758214e-01]\n",
      " [7.5912476e-04]\n",
      " [9.9950778e-01]\n",
      " [3.6335021e-02]\n",
      " [1.0000000e+00]\n",
      " [9.9968481e-01]\n",
      " [9.9865127e-01]\n",
      " [1.1920929e-07]\n",
      " [9.9999297e-01]\n",
      " [2.1278858e-05]\n",
      " [0.0000000e+00]\n",
      " [9.4175339e-06]\n",
      " [9.5721889e-01]\n",
      " [9.9771583e-01]\n",
      " [2.5662780e-04]\n",
      " [9.9996841e-01]\n",
      " [9.9980116e-01]\n",
      " [7.8788400e-04]\n",
      " [9.9999118e-01]\n",
      " [1.0780096e-03]\n",
      " [9.5010054e-01]\n",
      " [9.9500567e-01]\n",
      " [1.7881393e-07]\n",
      " [9.9996793e-01]\n",
      " [9.9957836e-01]\n",
      " [0.0000000e+00]\n",
      " [2.3699185e-01]\n",
      " [0.0000000e+00]\n",
      " [9.4411236e-01]\n",
      " [9.9983597e-01]\n",
      " [9.9364877e-01]\n",
      " [9.9985337e-01]\n",
      " [3.1888485e-06]\n",
      " [9.2763817e-01]\n",
      " [9.9998081e-01]\n",
      " [9.9979210e-01]\n",
      " [9.9996793e-01]\n",
      " [3.0034810e-02]\n",
      " [9.9999988e-01]\n",
      " [9.6451211e-01]\n",
      " [0.0000000e+00]\n",
      " [1.1134961e-01]\n",
      " [1.4901161e-07]\n",
      " [9.9765670e-01]\n",
      " [3.4481287e-05]\n",
      " [9.9575400e-01]\n",
      " [9.1791153e-05]\n",
      " [9.9930739e-01]\n",
      " [1.3411045e-06]\n",
      " [2.9110909e-03]\n",
      " [9.9950206e-01]\n",
      " [9.9942183e-01]\n",
      " [9.9977171e-01]\n",
      " [9.9982423e-01]\n",
      " [1.6965270e-03]\n",
      " [9.9737108e-01]\n",
      " [9.9959475e-01]\n",
      " [9.9058151e-01]\n",
      " [9.9996257e-01]\n",
      " [1.1264324e-01]\n",
      " [9.9947882e-01]\n",
      " [1.8646419e-03]\n",
      " [9.9963307e-01]\n",
      " [9.9999267e-01]\n",
      " [8.1634521e-04]\n",
      " [9.9999100e-01]\n",
      " [1.7914176e-04]\n",
      " [8.9406967e-08]\n",
      " [9.9944031e-01]\n",
      " [9.9986863e-01]\n",
      " [9.9983847e-01]\n",
      " [8.1449342e-01]\n",
      " [9.9607110e-01]\n",
      " [9.9627805e-01]\n",
      " [9.9996835e-01]\n",
      " [2.1766931e-02]\n",
      " [9.9994326e-01]\n",
      " [9.9999505e-01]\n",
      " [3.1696260e-03]\n",
      " [9.9998087e-01]\n",
      " [9.9525869e-01]\n",
      " [9.9978793e-01]\n",
      " [7.0505130e-01]\n",
      " [5.9604645e-08]\n",
      " [9.9991572e-01]\n",
      " [3.5379559e-02]\n",
      " [9.9999917e-01]\n",
      " [9.9885798e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9952447e-01]\n",
      " [9.9932885e-01]\n",
      " [9.6490723e-01]\n",
      " [7.3233545e-03]\n",
      " [0.0000000e+00]\n",
      " [9.9996448e-01]\n",
      " [9.9813461e-01]\n",
      " [9.9593037e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "P = model.predict(X_test)\n",
    "print(P) # they are ooutputs of the sigmoid, interpreted as probabilities p(y = 1 | x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
