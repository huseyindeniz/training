{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow\n",
    "# direct tensorflow installation throws tensorboard version error on my env\n",
    "# so install tensorboard 2.0.0 first\n",
    "# ! pip install tensorboard==2.0.0\n",
    "# ! pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of 'data'\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: it is a Bunch object\n",
    "# this basically acts like a dictionary where you can treat the keys lie attributes\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'data' (the attribute) means the inout data\n",
    "data.data.shape\n",
    "# it has 569 samples, 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'targets'\n",
    "data.target\n",
    "# note how the targets are just 0s and 1s\n",
    "# normally, when you have K targets, they are labeled 0..K-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their meaning is not lost\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are also 569 corresponding targets\n",
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also determine the meaning of each feature\n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would put all of our imports at the top\n",
    "# but this lets us tell a story\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test sets\n",
    "# this lets us simulate how our model will perform in the future\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# you'll learn why scaling is needed in a later course\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/3-3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/500\n",
      "381/381 [==============================] - 1s 4ms/sample - loss: 0.7003 - accuracy: 0.5853 - val_loss: 0.6383 - val_accuracy: 0.6170\n",
      "Epoch 2/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.6358 - accuracy: 0.6614 - val_loss: 0.5758 - val_accuracy: 0.7074\n",
      "Epoch 3/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.5799 - accuracy: 0.7297 - val_loss: 0.5234 - val_accuracy: 0.7660\n",
      "Epoch 4/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.5320 - accuracy: 0.7822 - val_loss: 0.4800 - val_accuracy: 0.8032\n",
      "Epoch 5/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.4921 - accuracy: 0.8294 - val_loss: 0.4432 - val_accuracy: 0.8351\n",
      "Epoch 6/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.4578 - accuracy: 0.8556 - val_loss: 0.4120 - val_accuracy: 0.8511\n",
      "Epoch 7/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.4282 - accuracy: 0.8661 - val_loss: 0.3856 - val_accuracy: 0.8670\n",
      "Epoch 8/500\n",
      "381/381 [==============================] - 0s 211us/sample - loss: 0.4029 - accuracy: 0.8714 - val_loss: 0.3625 - val_accuracy: 0.8723\n",
      "Epoch 9/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.3805 - accuracy: 0.8898 - val_loss: 0.3430 - val_accuracy: 0.8883\n",
      "Epoch 10/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.3612 - accuracy: 0.9003 - val_loss: 0.3252 - val_accuracy: 0.8936\n",
      "Epoch 11/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.3438 - accuracy: 0.9029 - val_loss: 0.3094 - val_accuracy: 0.9149\n",
      "Epoch 12/500\n",
      "381/381 [==============================] - 0s 287us/sample - loss: 0.3280 - accuracy: 0.9108 - val_loss: 0.2956 - val_accuracy: 0.9202\n",
      "Epoch 13/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.3137 - accuracy: 0.9134 - val_loss: 0.2831 - val_accuracy: 0.9202\n",
      "Epoch 14/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.3008 - accuracy: 0.9134 - val_loss: 0.2720 - val_accuracy: 0.9309\n",
      "Epoch 15/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2891 - accuracy: 0.9160 - val_loss: 0.2618 - val_accuracy: 0.9415\n",
      "Epoch 16/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2782 - accuracy: 0.9186 - val_loss: 0.2525 - val_accuracy: 0.9468\n",
      "Epoch 17/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.2683 - accuracy: 0.9213 - val_loss: 0.2443 - val_accuracy: 0.9468\n",
      "Epoch 18/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2595 - accuracy: 0.9239 - val_loss: 0.2368 - val_accuracy: 0.9468\n",
      "Epoch 19/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2506 - accuracy: 0.9239 - val_loss: 0.2296 - val_accuracy: 0.9468\n",
      "Epoch 20/500\n",
      "381/381 [==============================] - 0s 198us/sample - loss: 0.2429 - accuracy: 0.9265 - val_loss: 0.2231 - val_accuracy: 0.9468\n",
      "Epoch 21/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2353 - accuracy: 0.9265 - val_loss: 0.2169 - val_accuracy: 0.9468\n",
      "Epoch 22/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2287 - accuracy: 0.9265 - val_loss: 0.2112 - val_accuracy: 0.9521\n",
      "Epoch 23/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2222 - accuracy: 0.9291 - val_loss: 0.2060 - val_accuracy: 0.9521\n",
      "Epoch 24/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.2161 - accuracy: 0.9318 - val_loss: 0.2013 - val_accuracy: 0.9521\n",
      "Epoch 25/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2108 - accuracy: 0.9344 - val_loss: 0.1967 - val_accuracy: 0.9521\n",
      "Epoch 26/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.2053 - accuracy: 0.9344 - val_loss: 0.1925 - val_accuracy: 0.9521\n",
      "Epoch 27/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.2005 - accuracy: 0.9344 - val_loss: 0.1884 - val_accuracy: 0.9521\n",
      "Epoch 28/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1957 - accuracy: 0.9370 - val_loss: 0.1847 - val_accuracy: 0.9521\n",
      "Epoch 29/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1915 - accuracy: 0.9370 - val_loss: 0.1811 - val_accuracy: 0.9521\n",
      "Epoch 30/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1871 - accuracy: 0.9423 - val_loss: 0.1778 - val_accuracy: 0.9574\n",
      "Epoch 31/500\n",
      "381/381 [==============================] - 0s 210us/sample - loss: 0.1833 - accuracy: 0.9449 - val_loss: 0.1745 - val_accuracy: 0.9574\n",
      "Epoch 32/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1796 - accuracy: 0.9449 - val_loss: 0.1715 - val_accuracy: 0.9574\n",
      "Epoch 33/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1762 - accuracy: 0.9449 - val_loss: 0.1687 - val_accuracy: 0.9574\n",
      "Epoch 34/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1727 - accuracy: 0.9475 - val_loss: 0.1660 - val_accuracy: 0.9574\n",
      "Epoch 35/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1696 - accuracy: 0.9475 - val_loss: 0.1634 - val_accuracy: 0.9628\n",
      "Epoch 36/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1666 - accuracy: 0.9475 - val_loss: 0.1610 - val_accuracy: 0.9628\n",
      "Epoch 37/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1638 - accuracy: 0.9501 - val_loss: 0.1585 - val_accuracy: 0.9628\n",
      "Epoch 38/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1610 - accuracy: 0.9501 - val_loss: 0.1563 - val_accuracy: 0.9628\n",
      "Epoch 39/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1583 - accuracy: 0.9501 - val_loss: 0.1543 - val_accuracy: 0.9628\n",
      "Epoch 40/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1559 - accuracy: 0.9501 - val_loss: 0.1523 - val_accuracy: 0.9681\n",
      "Epoch 41/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1536 - accuracy: 0.9501 - val_loss: 0.1503 - val_accuracy: 0.9681\n",
      "Epoch 42/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.1513 - accuracy: 0.9501 - val_loss: 0.1484 - val_accuracy: 0.9681\n",
      "Epoch 43/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1491 - accuracy: 0.9528 - val_loss: 0.1466 - val_accuracy: 0.9734\n",
      "Epoch 44/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1471 - accuracy: 0.9528 - val_loss: 0.1449 - val_accuracy: 0.9734\n",
      "Epoch 45/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1450 - accuracy: 0.9554 - val_loss: 0.1432 - val_accuracy: 0.9734\n",
      "Epoch 46/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1431 - accuracy: 0.9580 - val_loss: 0.1416 - val_accuracy: 0.9734\n",
      "Epoch 47/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1413 - accuracy: 0.9580 - val_loss: 0.1400 - val_accuracy: 0.9734\n",
      "Epoch 48/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1396 - accuracy: 0.9580 - val_loss: 0.1386 - val_accuracy: 0.9734\n",
      "Epoch 49/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1378 - accuracy: 0.9580 - val_loss: 0.1371 - val_accuracy: 0.9734\n",
      "Epoch 50/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1362 - accuracy: 0.9580 - val_loss: 0.1357 - val_accuracy: 0.9734\n",
      "Epoch 51/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1346 - accuracy: 0.9633 - val_loss: 0.1344 - val_accuracy: 0.9734\n",
      "Epoch 52/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.1331 - accuracy: 0.9633 - val_loss: 0.1331 - val_accuracy: 0.9734\n",
      "Epoch 53/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1316 - accuracy: 0.9659 - val_loss: 0.1318 - val_accuracy: 0.9734\n",
      "Epoch 54/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1302 - accuracy: 0.9659 - val_loss: 0.1307 - val_accuracy: 0.9734\n",
      "Epoch 55/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1288 - accuracy: 0.9659 - val_loss: 0.1295 - val_accuracy: 0.9734\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1275 - accuracy: 0.9659 - val_loss: 0.1284 - val_accuracy: 0.9734\n",
      "Epoch 57/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1262 - accuracy: 0.9659 - val_loss: 0.1273 - val_accuracy: 0.9734\n",
      "Epoch 58/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.1250 - accuracy: 0.9659 - val_loss: 0.1262 - val_accuracy: 0.9734\n",
      "Epoch 59/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1238 - accuracy: 0.9659 - val_loss: 0.1252 - val_accuracy: 0.9734\n",
      "Epoch 60/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1226 - accuracy: 0.9659 - val_loss: 0.1242 - val_accuracy: 0.9734\n",
      "Epoch 61/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1215 - accuracy: 0.9659 - val_loss: 0.1233 - val_accuracy: 0.9734\n",
      "Epoch 62/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1205 - accuracy: 0.9659 - val_loss: 0.1224 - val_accuracy: 0.9734\n",
      "Epoch 63/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1193 - accuracy: 0.9659 - val_loss: 0.1215 - val_accuracy: 0.9734\n",
      "Epoch 64/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1183 - accuracy: 0.9659 - val_loss: 0.1206 - val_accuracy: 0.9734\n",
      "Epoch 65/500\n",
      "381/381 [==============================] - 0s 211us/sample - loss: 0.1173 - accuracy: 0.9659 - val_loss: 0.1198 - val_accuracy: 0.9734\n",
      "Epoch 66/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1163 - accuracy: 0.9659 - val_loss: 0.1190 - val_accuracy: 0.9734\n",
      "Epoch 67/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1155 - accuracy: 0.9659 - val_loss: 0.1181 - val_accuracy: 0.9734\n",
      "Epoch 68/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1146 - accuracy: 0.9659 - val_loss: 0.1174 - val_accuracy: 0.9734\n",
      "Epoch 69/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1136 - accuracy: 0.9659 - val_loss: 0.1167 - val_accuracy: 0.9734\n",
      "Epoch 70/500\n",
      "381/381 [==============================] - 0s 211us/sample - loss: 0.1127 - accuracy: 0.9659 - val_loss: 0.1159 - val_accuracy: 0.9734\n",
      "Epoch 71/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1119 - accuracy: 0.9659 - val_loss: 0.1152 - val_accuracy: 0.9734\n",
      "Epoch 72/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1110 - accuracy: 0.9659 - val_loss: 0.1145 - val_accuracy: 0.9734\n",
      "Epoch 73/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.1103 - accuracy: 0.9659 - val_loss: 0.1137 - val_accuracy: 0.9734\n",
      "Epoch 74/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1095 - accuracy: 0.9685 - val_loss: 0.1130 - val_accuracy: 0.9734\n",
      "Epoch 75/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1087 - accuracy: 0.9685 - val_loss: 0.1124 - val_accuracy: 0.9734\n",
      "Epoch 76/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1080 - accuracy: 0.9685 - val_loss: 0.1118 - val_accuracy: 0.9734\n",
      "Epoch 77/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.1072 - accuracy: 0.9685 - val_loss: 0.1111 - val_accuracy: 0.9734\n",
      "Epoch 78/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1065 - accuracy: 0.9685 - val_loss: 0.1105 - val_accuracy: 0.9734\n",
      "Epoch 79/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1058 - accuracy: 0.9685 - val_loss: 0.1099 - val_accuracy: 0.9734\n",
      "Epoch 80/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.1051 - accuracy: 0.9685 - val_loss: 0.1094 - val_accuracy: 0.9734\n",
      "Epoch 81/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1045 - accuracy: 0.9685 - val_loss: 0.1089 - val_accuracy: 0.9734\n",
      "Epoch 82/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.1038 - accuracy: 0.9711 - val_loss: 0.1083 - val_accuracy: 0.9734\n",
      "Epoch 83/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1032 - accuracy: 0.9711 - val_loss: 0.1078 - val_accuracy: 0.9734\n",
      "Epoch 84/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1026 - accuracy: 0.9711 - val_loss: 0.1072 - val_accuracy: 0.9734\n",
      "Epoch 85/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.1020 - accuracy: 0.9738 - val_loss: 0.1066 - val_accuracy: 0.9734\n",
      "Epoch 86/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1013 - accuracy: 0.9738 - val_loss: 0.1062 - val_accuracy: 0.9734\n",
      "Epoch 87/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.1008 - accuracy: 0.9738 - val_loss: 0.1058 - val_accuracy: 0.9734\n",
      "Epoch 88/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.1002 - accuracy: 0.9738 - val_loss: 0.1053 - val_accuracy: 0.9734\n",
      "Epoch 89/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0996 - accuracy: 0.9764 - val_loss: 0.1049 - val_accuracy: 0.9734\n",
      "Epoch 90/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0991 - accuracy: 0.9764 - val_loss: 0.1043 - val_accuracy: 0.9734\n",
      "Epoch 91/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0986 - accuracy: 0.9764 - val_loss: 0.1038 - val_accuracy: 0.9734\n",
      "Epoch 92/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0980 - accuracy: 0.9764 - val_loss: 0.1034 - val_accuracy: 0.9734\n",
      "Epoch 93/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0975 - accuracy: 0.9764 - val_loss: 0.1030 - val_accuracy: 0.9734\n",
      "Epoch 94/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0970 - accuracy: 0.9764 - val_loss: 0.1025 - val_accuracy: 0.9734\n",
      "Epoch 95/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0965 - accuracy: 0.9764 - val_loss: 0.1021 - val_accuracy: 0.9734\n",
      "Epoch 96/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0960 - accuracy: 0.9764 - val_loss: 0.1018 - val_accuracy: 0.9734\n",
      "Epoch 97/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0956 - accuracy: 0.9764 - val_loss: 0.1015 - val_accuracy: 0.9734\n",
      "Epoch 98/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0951 - accuracy: 0.9764 - val_loss: 0.1010 - val_accuracy: 0.9734\n",
      "Epoch 99/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0947 - accuracy: 0.9764 - val_loss: 0.1005 - val_accuracy: 0.9734\n",
      "Epoch 100/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0942 - accuracy: 0.9764 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
      "Epoch 101/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0937 - accuracy: 0.9764 - val_loss: 0.0999 - val_accuracy: 0.9734\n",
      "Epoch 102/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0933 - accuracy: 0.9764 - val_loss: 0.0996 - val_accuracy: 0.9734\n",
      "Epoch 103/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0929 - accuracy: 0.9764 - val_loss: 0.0993 - val_accuracy: 0.9734\n",
      "Epoch 104/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0925 - accuracy: 0.9764 - val_loss: 0.0989 - val_accuracy: 0.9734\n",
      "Epoch 105/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0921 - accuracy: 0.9764 - val_loss: 0.0986 - val_accuracy: 0.9734\n",
      "Epoch 106/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0916 - accuracy: 0.9764 - val_loss: 0.0982 - val_accuracy: 0.9734\n",
      "Epoch 107/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0913 - accuracy: 0.9764 - val_loss: 0.0979 - val_accuracy: 0.9734\n",
      "Epoch 108/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0909 - accuracy: 0.9764 - val_loss: 0.0975 - val_accuracy: 0.9734\n",
      "Epoch 109/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0905 - accuracy: 0.9764 - val_loss: 0.0972 - val_accuracy: 0.9734\n",
      "Epoch 110/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0901 - accuracy: 0.9790 - val_loss: 0.0970 - val_accuracy: 0.9734\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0897 - accuracy: 0.9790 - val_loss: 0.0966 - val_accuracy: 0.9734\n",
      "Epoch 112/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0894 - accuracy: 0.9790 - val_loss: 0.0962 - val_accuracy: 0.9734\n",
      "Epoch 113/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0890 - accuracy: 0.9790 - val_loss: 0.0960 - val_accuracy: 0.9681\n",
      "Epoch 114/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0886 - accuracy: 0.9790 - val_loss: 0.0958 - val_accuracy: 0.9681\n",
      "Epoch 115/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0883 - accuracy: 0.9790 - val_loss: 0.0954 - val_accuracy: 0.9681\n",
      "Epoch 116/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0880 - accuracy: 0.9790 - val_loss: 0.0952 - val_accuracy: 0.9628\n",
      "Epoch 117/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0876 - accuracy: 0.9790 - val_loss: 0.0948 - val_accuracy: 0.9628\n",
      "Epoch 118/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.0947 - val_accuracy: 0.9628\n",
      "Epoch 119/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0870 - accuracy: 0.9790 - val_loss: 0.0943 - val_accuracy: 0.9628\n",
      "Epoch 120/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0866 - accuracy: 0.9790 - val_loss: 0.0941 - val_accuracy: 0.9628\n",
      "Epoch 121/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0863 - accuracy: 0.9790 - val_loss: 0.0938 - val_accuracy: 0.9628\n",
      "Epoch 122/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0860 - accuracy: 0.9790 - val_loss: 0.0937 - val_accuracy: 0.9628\n",
      "Epoch 123/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0857 - accuracy: 0.9790 - val_loss: 0.0934 - val_accuracy: 0.9628\n",
      "Epoch 124/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0854 - accuracy: 0.9790 - val_loss: 0.0930 - val_accuracy: 0.9628\n",
      "Epoch 125/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0851 - accuracy: 0.9790 - val_loss: 0.0929 - val_accuracy: 0.9628\n",
      "Epoch 126/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0848 - accuracy: 0.9790 - val_loss: 0.0928 - val_accuracy: 0.9628\n",
      "Epoch 127/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0845 - accuracy: 0.9790 - val_loss: 0.0925 - val_accuracy: 0.9628\n",
      "Epoch 128/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0843 - accuracy: 0.9790 - val_loss: 0.0923 - val_accuracy: 0.9628\n",
      "Epoch 129/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0840 - accuracy: 0.9790 - val_loss: 0.0920 - val_accuracy: 0.9628\n",
      "Epoch 130/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0837 - accuracy: 0.9790 - val_loss: 0.0919 - val_accuracy: 0.9628\n",
      "Epoch 131/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0834 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9628\n",
      "Epoch 132/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0831 - accuracy: 0.9790 - val_loss: 0.0914 - val_accuracy: 0.9628\n",
      "Epoch 133/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0829 - accuracy: 0.9790 - val_loss: 0.0912 - val_accuracy: 0.9628\n",
      "Epoch 134/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0826 - accuracy: 0.9790 - val_loss: 0.0911 - val_accuracy: 0.9628\n",
      "Epoch 135/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0824 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9628\n",
      "Epoch 136/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0821 - accuracy: 0.9790 - val_loss: 0.0906 - val_accuracy: 0.9628\n",
      "Epoch 137/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0818 - accuracy: 0.9790 - val_loss: 0.0904 - val_accuracy: 0.9628\n",
      "Epoch 138/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0816 - accuracy: 0.9790 - val_loss: 0.0902 - val_accuracy: 0.9628\n",
      "Epoch 139/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0813 - accuracy: 0.9790 - val_loss: 0.0901 - val_accuracy: 0.9628\n",
      "Epoch 140/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0811 - accuracy: 0.9790 - val_loss: 0.0900 - val_accuracy: 0.9628\n",
      "Epoch 141/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0809 - accuracy: 0.9790 - val_loss: 0.0897 - val_accuracy: 0.9628\n",
      "Epoch 142/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0806 - accuracy: 0.9816 - val_loss: 0.0896 - val_accuracy: 0.9628\n",
      "Epoch 143/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0804 - accuracy: 0.9816 - val_loss: 0.0894 - val_accuracy: 0.9628\n",
      "Epoch 144/500\n",
      "381/381 [==============================] - 0s 181us/sample - loss: 0.0801 - accuracy: 0.9816 - val_loss: 0.0893 - val_accuracy: 0.9574\n",
      "Epoch 145/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0799 - accuracy: 0.9816 - val_loss: 0.0891 - val_accuracy: 0.9574\n",
      "Epoch 146/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0797 - accuracy: 0.9816 - val_loss: 0.0888 - val_accuracy: 0.9574\n",
      "Epoch 147/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0795 - accuracy: 0.9816 - val_loss: 0.0887 - val_accuracy: 0.9574\n",
      "Epoch 148/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0793 - accuracy: 0.9816 - val_loss: 0.0886 - val_accuracy: 0.9574\n",
      "Epoch 149/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0790 - accuracy: 0.9816 - val_loss: 0.0884 - val_accuracy: 0.9574\n",
      "Epoch 150/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0788 - accuracy: 0.9816 - val_loss: 0.0883 - val_accuracy: 0.9574\n",
      "Epoch 151/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0786 - accuracy: 0.9816 - val_loss: 0.0881 - val_accuracy: 0.9574\n",
      "Epoch 152/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0784 - accuracy: 0.9816 - val_loss: 0.0880 - val_accuracy: 0.9574\n",
      "Epoch 153/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0782 - accuracy: 0.9816 - val_loss: 0.0879 - val_accuracy: 0.9574\n",
      "Epoch 154/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0780 - accuracy: 0.9816 - val_loss: 0.0877 - val_accuracy: 0.9574\n",
      "Epoch 155/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0778 - accuracy: 0.9816 - val_loss: 0.0876 - val_accuracy: 0.9574\n",
      "Epoch 156/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0776 - accuracy: 0.9816 - val_loss: 0.0875 - val_accuracy: 0.9574\n",
      "Epoch 157/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0774 - accuracy: 0.9816 - val_loss: 0.0873 - val_accuracy: 0.9574\n",
      "Epoch 158/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0772 - accuracy: 0.9816 - val_loss: 0.0872 - val_accuracy: 0.9574\n",
      "Epoch 159/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0770 - accuracy: 0.9816 - val_loss: 0.0870 - val_accuracy: 0.9574\n",
      "Epoch 160/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0768 - accuracy: 0.9816 - val_loss: 0.0869 - val_accuracy: 0.9574\n",
      "Epoch 161/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0766 - accuracy: 0.9816 - val_loss: 0.0869 - val_accuracy: 0.9574\n",
      "Epoch 162/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0765 - accuracy: 0.9816 - val_loss: 0.0866 - val_accuracy: 0.9574\n",
      "Epoch 163/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0763 - accuracy: 0.9816 - val_loss: 0.0866 - val_accuracy: 0.9574\n",
      "Epoch 164/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0761 - accuracy: 0.9816 - val_loss: 0.0865 - val_accuracy: 0.9574\n",
      "Epoch 165/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0759 - accuracy: 0.9816 - val_loss: 0.0864 - val_accuracy: 0.9574\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0757 - accuracy: 0.9816 - val_loss: 0.0863 - val_accuracy: 0.9574\n",
      "Epoch 167/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0756 - accuracy: 0.9816 - val_loss: 0.0861 - val_accuracy: 0.9574\n",
      "Epoch 168/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0754 - accuracy: 0.9816 - val_loss: 0.0860 - val_accuracy: 0.9574\n",
      "Epoch 169/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0752 - accuracy: 0.9816 - val_loss: 0.0859 - val_accuracy: 0.9574\n",
      "Epoch 170/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0751 - accuracy: 0.9816 - val_loss: 0.0858 - val_accuracy: 0.9574\n",
      "Epoch 171/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0749 - accuracy: 0.9816 - val_loss: 0.0855 - val_accuracy: 0.9574\n",
      "Epoch 172/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0747 - accuracy: 0.9816 - val_loss: 0.0856 - val_accuracy: 0.9574\n",
      "Epoch 173/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0746 - accuracy: 0.9816 - val_loss: 0.0853 - val_accuracy: 0.9574\n",
      "Epoch 174/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0744 - accuracy: 0.9816 - val_loss: 0.0854 - val_accuracy: 0.9574\n",
      "Epoch 175/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0742 - accuracy: 0.9816 - val_loss: 0.0851 - val_accuracy: 0.9574\n",
      "Epoch 176/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0741 - accuracy: 0.9816 - val_loss: 0.0852 - val_accuracy: 0.9574\n",
      "Epoch 177/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0739 - accuracy: 0.9816 - val_loss: 0.0851 - val_accuracy: 0.9574\n",
      "Epoch 178/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0738 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9574\n",
      "Epoch 179/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0736 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9628\n",
      "Epoch 180/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0735 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9628\n",
      "Epoch 181/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0734 - accuracy: 0.9816 - val_loss: 0.0845 - val_accuracy: 0.9628\n",
      "Epoch 182/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0731 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9628\n",
      "Epoch 183/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0730 - accuracy: 0.9816 - val_loss: 0.0843 - val_accuracy: 0.9628\n",
      "Epoch 184/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0728 - accuracy: 0.9816 - val_loss: 0.0842 - val_accuracy: 0.9628\n",
      "Epoch 185/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0727 - accuracy: 0.9816 - val_loss: 0.0843 - val_accuracy: 0.9628\n",
      "Epoch 186/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0726 - accuracy: 0.9816 - val_loss: 0.0843 - val_accuracy: 0.9628\n",
      "Epoch 187/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0724 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9628\n",
      "Epoch 188/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0723 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9628\n",
      "Epoch 189/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0722 - accuracy: 0.9816 - val_loss: 0.0839 - val_accuracy: 0.9628\n",
      "Epoch 190/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0720 - accuracy: 0.9816 - val_loss: 0.0837 - val_accuracy: 0.9628\n",
      "Epoch 191/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0719 - accuracy: 0.9816 - val_loss: 0.0837 - val_accuracy: 0.9628\n",
      "Epoch 192/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0717 - accuracy: 0.9816 - val_loss: 0.0837 - val_accuracy: 0.9628\n",
      "Epoch 193/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0717 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 194/500\n",
      "381/381 [==============================] - 0s 187us/sample - loss: 0.0715 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 195/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0714 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9628\n",
      "Epoch 196/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0712 - accuracy: 0.9816 - val_loss: 0.0834 - val_accuracy: 0.9628\n",
      "Epoch 197/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0711 - accuracy: 0.9816 - val_loss: 0.0834 - val_accuracy: 0.9628\n",
      "Epoch 198/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0710 - accuracy: 0.9816 - val_loss: 0.0832 - val_accuracy: 0.9628\n",
      "Epoch 199/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0708 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9628\n",
      "Epoch 200/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0707 - accuracy: 0.9816 - val_loss: 0.0832 - val_accuracy: 0.9628\n",
      "Epoch 201/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0706 - accuracy: 0.9816 - val_loss: 0.0831 - val_accuracy: 0.9628\n",
      "Epoch 202/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0705 - accuracy: 0.9816 - val_loss: 0.0831 - val_accuracy: 0.9628\n",
      "Epoch 203/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0703 - accuracy: 0.9816 - val_loss: 0.0831 - val_accuracy: 0.9628\n",
      "Epoch 204/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0702 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9628\n",
      "Epoch 205/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0701 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9628\n",
      "Epoch 206/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0700 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9628\n",
      "Epoch 207/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0699 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 208/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0697 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 209/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0697 - accuracy: 0.9816 - val_loss: 0.0828 - val_accuracy: 0.9628\n",
      "Epoch 210/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0695 - accuracy: 0.9816 - val_loss: 0.0828 - val_accuracy: 0.9628\n",
      "Epoch 211/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0694 - accuracy: 0.9816 - val_loss: 0.0826 - val_accuracy: 0.9628\n",
      "Epoch 212/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0693 - accuracy: 0.9816 - val_loss: 0.0826 - val_accuracy: 0.9628\n",
      "Epoch 213/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0692 - accuracy: 0.9816 - val_loss: 0.0826 - val_accuracy: 0.9628\n",
      "Epoch 214/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0691 - accuracy: 0.9816 - val_loss: 0.0825 - val_accuracy: 0.9628\n",
      "Epoch 215/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0690 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9628\n",
      "Epoch 216/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0688 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 217/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0687 - accuracy: 0.9816 - val_loss: 0.0823 - val_accuracy: 0.9628\n",
      "Epoch 218/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0686 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 219/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0685 - accuracy: 0.9816 - val_loss: 0.0821 - val_accuracy: 0.9628\n",
      "Epoch 220/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0685 - accuracy: 0.9816 - val_loss: 0.0821 - val_accuracy: 0.9628\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0683 - accuracy: 0.9816 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 222/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0682 - accuracy: 0.9816 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 223/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0681 - accuracy: 0.9816 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 224/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0680 - accuracy: 0.9816 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 225/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0821 - val_accuracy: 0.9628\n",
      "Epoch 226/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 227/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0817 - val_accuracy: 0.9628\n",
      "Epoch 228/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0676 - accuracy: 0.9816 - val_loss: 0.0817 - val_accuracy: 0.9628\n",
      "Epoch 229/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 230/500\n",
      "381/381 [==============================] - 0s 211us/sample - loss: 0.0674 - accuracy: 0.9816 - val_loss: 0.0818 - val_accuracy: 0.9628\n",
      "Epoch 231/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0673 - accuracy: 0.9816 - val_loss: 0.0817 - val_accuracy: 0.9628\n",
      "Epoch 232/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0672 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 233/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0671 - accuracy: 0.9816 - val_loss: 0.0817 - val_accuracy: 0.9628\n",
      "Epoch 234/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 235/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0669 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 236/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0668 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 237/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0667 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 238/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0667 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 239/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0666 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 240/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0665 - accuracy: 0.9816 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 241/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0664 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 242/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0663 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 243/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0662 - accuracy: 0.9816 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 244/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 245/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 246/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0659 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 247/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0659 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9628\n",
      "Epoch 248/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0658 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 249/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0657 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 250/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 251/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0655 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 252/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0654 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 253/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0653 - accuracy: 0.9816 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 254/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0653 - accuracy: 0.9816 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 255/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0652 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 256/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0651 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 257/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0650 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 258/500\n",
      "381/381 [==============================] - 0s 204us/sample - loss: 0.0649 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 259/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 260/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0648 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 261/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9628\n",
      "Epoch 262/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 263/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9628\n",
      "Epoch 264/500\n",
      "381/381 [==============================] - 0s 221us/sample - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 265/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0644 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 266/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0643 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 267/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 268/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 269/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 270/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 271/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 272/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0639 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 273/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 274/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 275/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 277/500\n",
      "381/381 [==============================] - 0s 175us/sample - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 278/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9628\n",
      "Epoch 279/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 280/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 281/500\n",
      "381/381 [==============================] - 0s 212us/sample - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9628\n",
      "Epoch 282/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9628\n",
      "Epoch 283/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 284/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9628\n",
      "Epoch 285/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0629 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 286/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9628\n",
      "Epoch 287/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0628 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 288/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0628 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 289/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9628\n",
      "Epoch 290/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0626 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9628\n",
      "Epoch 291/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0625 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9628\n",
      "Epoch 292/500\n",
      "381/381 [==============================] - 0s 200us/sample - loss: 0.0625 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 293/500\n",
      "381/381 [==============================] - 0s 261us/sample - loss: 0.0624 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9628\n",
      "Epoch 294/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0623 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 295/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9628\n",
      "Epoch 296/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0622 - accuracy: 0.9816 - val_loss: 0.0820 - val_accuracy: 0.9628\n",
      "Epoch 297/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0622 - accuracy: 0.9816 - val_loss: 0.0819 - val_accuracy: 0.9628\n",
      "Epoch 298/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0621 - accuracy: 0.9816 - val_loss: 0.0823 - val_accuracy: 0.9628\n",
      "Epoch 299/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 300/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0619 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 301/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0619 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 302/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0618 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9628\n",
      "Epoch 303/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0825 - val_accuracy: 0.9628\n",
      "Epoch 304/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0823 - val_accuracy: 0.9628\n",
      "Epoch 305/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0825 - val_accuracy: 0.9628\n",
      "Epoch 306/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.0825 - val_accuracy: 0.9628\n",
      "Epoch 307/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9628\n",
      "Epoch 308/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0823 - val_accuracy: 0.9628\n",
      "Epoch 309/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0614 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9628\n",
      "Epoch 310/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0613 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9628\n",
      "Epoch 311/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0613 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 312/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 313/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 314/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0611 - accuracy: 0.9816 - val_loss: 0.0826 - val_accuracy: 0.9628\n",
      "Epoch 315/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0610 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9628\n",
      "Epoch 316/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0610 - accuracy: 0.9816 - val_loss: 0.0830 - val_accuracy: 0.9628\n",
      "Epoch 317/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0609 - accuracy: 0.9816 - val_loss: 0.0828 - val_accuracy: 0.9628\n",
      "Epoch 318/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0830 - val_accuracy: 0.9628\n",
      "Epoch 319/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9628\n",
      "Epoch 320/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9628\n",
      "Epoch 321/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.0834 - val_accuracy: 0.9628\n",
      "Epoch 322/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.0832 - val_accuracy: 0.9628\n",
      "Epoch 323/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9628\n",
      "Epoch 324/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0605 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 325/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0605 - accuracy: 0.9816 - val_loss: 0.0830 - val_accuracy: 0.9628\n",
      "Epoch 326/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0604 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 327/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0603 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9628\n",
      "Epoch 328/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0603 - accuracy: 0.9816 - val_loss: 0.0836 - val_accuracy: 0.9628\n",
      "Epoch 329/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 330/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.0834 - val_accuracy: 0.9628\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9628\n",
      "Epoch 332/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0836 - val_accuracy: 0.9628\n",
      "Epoch 333/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0838 - val_accuracy: 0.9628\n",
      "Epoch 334/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0840 - val_accuracy: 0.9628\n",
      "Epoch 335/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0836 - val_accuracy: 0.9628\n",
      "Epoch 336/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.0839 - val_accuracy: 0.9628\n",
      "Epoch 337/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.0839 - val_accuracy: 0.9628\n",
      "Epoch 338/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0597 - accuracy: 0.9816 - val_loss: 0.0839 - val_accuracy: 0.9628\n",
      "Epoch 339/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0597 - accuracy: 0.9816 - val_loss: 0.0840 - val_accuracy: 0.9628\n",
      "Epoch 340/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9628\n",
      "Epoch 341/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.0845 - val_accuracy: 0.9628\n",
      "Epoch 342/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0595 - accuracy: 0.9816 - val_loss: 0.0843 - val_accuracy: 0.9628\n",
      "Epoch 343/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0595 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9628\n",
      "Epoch 344/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9628\n",
      "Epoch 345/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.0842 - val_accuracy: 0.9628\n",
      "Epoch 346/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0845 - val_accuracy: 0.9628\n",
      "Epoch 347/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0845 - val_accuracy: 0.9628\n",
      "Epoch 348/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0592 - accuracy: 0.9816 - val_loss: 0.0847 - val_accuracy: 0.9628\n",
      "Epoch 349/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0592 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9628\n",
      "Epoch 350/500\n",
      "381/381 [==============================] - 0s 211us/sample - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.0846 - val_accuracy: 0.9628\n",
      "Epoch 351/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0846 - val_accuracy: 0.9628\n",
      "Epoch 352/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0848 - val_accuracy: 0.9628\n",
      "Epoch 353/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9628\n",
      "Epoch 354/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0589 - accuracy: 0.9816 - val_loss: 0.0850 - val_accuracy: 0.9574\n",
      "Epoch 355/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0852 - val_accuracy: 0.9574\n",
      "Epoch 356/500\n",
      "381/381 [==============================] - 0s 187us/sample - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0851 - val_accuracy: 0.9574\n",
      "Epoch 357/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.0854 - val_accuracy: 0.9574\n",
      "Epoch 358/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.0852 - val_accuracy: 0.9574\n",
      "Epoch 359/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.0856 - val_accuracy: 0.9574\n",
      "Epoch 360/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0856 - val_accuracy: 0.9574\n",
      "Epoch 361/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.0855 - val_accuracy: 0.9574\n",
      "Epoch 362/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.0856 - val_accuracy: 0.9574\n",
      "Epoch 363/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.0854 - val_accuracy: 0.9574\n",
      "Epoch 364/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0584 - accuracy: 0.9816 - val_loss: 0.0857 - val_accuracy: 0.9574\n",
      "Epoch 365/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.0858 - val_accuracy: 0.9574\n",
      "Epoch 366/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.0859 - val_accuracy: 0.9574\n",
      "Epoch 367/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0582 - accuracy: 0.9816 - val_loss: 0.0860 - val_accuracy: 0.9574\n",
      "Epoch 368/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0582 - accuracy: 0.9816 - val_loss: 0.0861 - val_accuracy: 0.9574\n",
      "Epoch 369/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0582 - accuracy: 0.9816 - val_loss: 0.0865 - val_accuracy: 0.9574\n",
      "Epoch 370/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.0864 - val_accuracy: 0.9574\n",
      "Epoch 371/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.0866 - val_accuracy: 0.9574\n",
      "Epoch 372/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.0867 - val_accuracy: 0.9574\n",
      "Epoch 373/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.0862 - val_accuracy: 0.9574\n",
      "Epoch 374/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.0864 - val_accuracy: 0.9574\n",
      "Epoch 375/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.0864 - val_accuracy: 0.9574\n",
      "Epoch 376/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9574\n",
      "Epoch 377/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0578 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9574\n",
      "Epoch 378/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9574\n",
      "Epoch 379/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0871 - val_accuracy: 0.9574\n",
      "Epoch 380/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9574\n",
      "Epoch 381/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9574\n",
      "Epoch 382/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0875 - val_accuracy: 0.9574\n",
      "Epoch 383/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0874 - val_accuracy: 0.9574\n",
      "Epoch 384/500\n",
      "381/381 [==============================] - 0s 252us/sample - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0872 - val_accuracy: 0.9574\n",
      "Epoch 385/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.0874 - val_accuracy: 0.9574\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0573 - accuracy: 0.9816 - val_loss: 0.0876 - val_accuracy: 0.9574\n",
      "Epoch 387/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0573 - accuracy: 0.9816 - val_loss: 0.0874 - val_accuracy: 0.9574\n",
      "Epoch 388/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0875 - val_accuracy: 0.9574\n",
      "Epoch 389/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0877 - val_accuracy: 0.9574\n",
      "Epoch 390/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0878 - val_accuracy: 0.9574\n",
      "Epoch 391/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0883 - val_accuracy: 0.9574\n",
      "Epoch 392/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0883 - val_accuracy: 0.9574\n",
      "Epoch 393/500\n",
      "381/381 [==============================] - 0s 250us/sample - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.0883 - val_accuracy: 0.9574\n",
      "Epoch 394/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.0882 - val_accuracy: 0.9574\n",
      "Epoch 395/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0883 - val_accuracy: 0.9574\n",
      "Epoch 396/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0881 - val_accuracy: 0.9574\n",
      "Epoch 397/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0886 - val_accuracy: 0.9574\n",
      "Epoch 398/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0887 - val_accuracy: 0.9574\n",
      "Epoch 399/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0891 - val_accuracy: 0.9574\n",
      "Epoch 400/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0890 - val_accuracy: 0.9574\n",
      "Epoch 401/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0886 - val_accuracy: 0.9574\n",
      "Epoch 402/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0889 - val_accuracy: 0.9574\n",
      "Epoch 403/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0893 - val_accuracy: 0.9574\n",
      "Epoch 404/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0895 - val_accuracy: 0.9574\n",
      "Epoch 405/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0891 - val_accuracy: 0.9574\n",
      "Epoch 406/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.0893 - val_accuracy: 0.9574\n",
      "Epoch 407/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0894 - val_accuracy: 0.9574\n",
      "Epoch 408/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0895 - val_accuracy: 0.9574\n",
      "Epoch 409/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0890 - val_accuracy: 0.9574\n",
      "Epoch 410/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0895 - val_accuracy: 0.9574\n",
      "Epoch 411/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0899 - val_accuracy: 0.9574\n",
      "Epoch 412/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0901 - val_accuracy: 0.9574\n",
      "Epoch 413/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0901 - val_accuracy: 0.9574\n",
      "Epoch 414/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0901 - val_accuracy: 0.9574\n",
      "Epoch 415/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0903 - val_accuracy: 0.9574\n",
      "Epoch 416/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.0901 - val_accuracy: 0.9574\n",
      "Epoch 417/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.0900 - val_accuracy: 0.9574\n",
      "Epoch 418/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0560 - accuracy: 0.9843 - val_loss: 0.0903 - val_accuracy: 0.9574\n",
      "Epoch 419/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0907 - val_accuracy: 0.9574\n",
      "Epoch 420/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0908 - val_accuracy: 0.9574\n",
      "Epoch 421/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0558 - accuracy: 0.9843 - val_loss: 0.0907 - val_accuracy: 0.9574\n",
      "Epoch 422/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.0905 - val_accuracy: 0.9574\n",
      "Epoch 423/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.0909 - val_accuracy: 0.9574\n",
      "Epoch 424/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.0910 - val_accuracy: 0.9574\n",
      "Epoch 425/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0557 - accuracy: 0.9816 - val_loss: 0.0914 - val_accuracy: 0.9574\n",
      "Epoch 426/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.0914 - val_accuracy: 0.9574\n",
      "Epoch 427/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.0915 - val_accuracy: 0.9574\n",
      "Epoch 428/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.0916 - val_accuracy: 0.9574\n",
      "Epoch 429/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.0919 - val_accuracy: 0.9574\n",
      "Epoch 430/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.0917 - val_accuracy: 0.9574\n",
      "Epoch 431/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0918 - val_accuracy: 0.9574\n",
      "Epoch 432/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0920 - val_accuracy: 0.9574\n",
      "Epoch 433/500\n",
      "381/381 [==============================] - 0s 219us/sample - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0918 - val_accuracy: 0.9574\n",
      "Epoch 434/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0553 - accuracy: 0.9843 - val_loss: 0.0921 - val_accuracy: 0.9574\n",
      "Epoch 435/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0553 - accuracy: 0.9816 - val_loss: 0.0927 - val_accuracy: 0.9574\n",
      "Epoch 436/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0552 - accuracy: 0.9843 - val_loss: 0.0928 - val_accuracy: 0.9574\n",
      "Epoch 437/500\n",
      "381/381 [==============================] - 0s 287us/sample - loss: 0.0552 - accuracy: 0.9843 - val_loss: 0.0926 - val_accuracy: 0.9574\n",
      "Epoch 438/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0552 - accuracy: 0.9843 - val_loss: 0.0927 - val_accuracy: 0.9574\n",
      "Epoch 439/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.0927 - val_accuracy: 0.9574\n",
      "Epoch 440/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.0931 - val_accuracy: 0.9574\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 215us/sample - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.0934 - val_accuracy: 0.9574\n",
      "Epoch 442/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0550 - accuracy: 0.9843 - val_loss: 0.0931 - val_accuracy: 0.9574\n",
      "Epoch 443/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0550 - accuracy: 0.9843 - val_loss: 0.0930 - val_accuracy: 0.9574\n",
      "Epoch 444/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.0933 - val_accuracy: 0.9574\n",
      "Epoch 445/500\n",
      "381/381 [==============================] - 0s 212us/sample - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.0933 - val_accuracy: 0.9574\n",
      "Epoch 446/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0931 - val_accuracy: 0.9574\n",
      "Epoch 447/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.0942 - val_accuracy: 0.9574\n",
      "Epoch 448/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0941 - val_accuracy: 0.9574\n",
      "Epoch 449/500\n",
      "381/381 [==============================] - 0s 168us/sample - loss: 0.0547 - accuracy: 0.9843 - val_loss: 0.0941 - val_accuracy: 0.9574\n",
      "Epoch 450/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0547 - accuracy: 0.9843 - val_loss: 0.0945 - val_accuracy: 0.9574\n",
      "Epoch 451/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.0948 - val_accuracy: 0.9574\n",
      "Epoch 452/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0546 - accuracy: 0.9843 - val_loss: 0.0946 - val_accuracy: 0.9574\n",
      "Epoch 453/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0546 - accuracy: 0.9843 - val_loss: 0.0947 - val_accuracy: 0.9574\n",
      "Epoch 454/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.0944 - val_accuracy: 0.9574\n",
      "Epoch 455/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.0950 - val_accuracy: 0.9574\n",
      "Epoch 456/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.0946 - val_accuracy: 0.9574\n",
      "Epoch 457/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0544 - accuracy: 0.9843 - val_loss: 0.0949 - val_accuracy: 0.9574\n",
      "Epoch 458/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0544 - accuracy: 0.9843 - val_loss: 0.0947 - val_accuracy: 0.9574\n",
      "Epoch 459/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0544 - accuracy: 0.9843 - val_loss: 0.0951 - val_accuracy: 0.9574\n",
      "Epoch 460/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0543 - accuracy: 0.9843 - val_loss: 0.0951 - val_accuracy: 0.9574\n",
      "Epoch 461/500\n",
      "381/381 [==============================] - 0s 251us/sample - loss: 0.0543 - accuracy: 0.9843 - val_loss: 0.0949 - val_accuracy: 0.9574\n",
      "Epoch 462/500\n",
      "381/381 [==============================] - 0s 255us/sample - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.0954 - val_accuracy: 0.9574\n",
      "Epoch 463/500\n",
      "381/381 [==============================] - 0s 220us/sample - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.0954 - val_accuracy: 0.9574\n",
      "Epoch 464/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.0950 - val_accuracy: 0.9574\n",
      "Epoch 465/500\n",
      "381/381 [==============================] - 0s 222us/sample - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.0955 - val_accuracy: 0.9574\n",
      "Epoch 466/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.0955 - val_accuracy: 0.9574\n",
      "Epoch 467/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.0956 - val_accuracy: 0.9574\n",
      "Epoch 468/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0540 - accuracy: 0.9843 - val_loss: 0.0960 - val_accuracy: 0.9574\n",
      "Epoch 469/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0540 - accuracy: 0.9843 - val_loss: 0.0961 - val_accuracy: 0.9574\n",
      "Epoch 470/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0539 - accuracy: 0.9843 - val_loss: 0.0966 - val_accuracy: 0.9574\n",
      "Epoch 471/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0539 - accuracy: 0.9843 - val_loss: 0.0963 - val_accuracy: 0.9574\n",
      "Epoch 472/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0538 - accuracy: 0.9843 - val_loss: 0.0964 - val_accuracy: 0.9574\n",
      "Epoch 473/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0538 - accuracy: 0.9843 - val_loss: 0.0963 - val_accuracy: 0.9574\n",
      "Epoch 474/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0539 - accuracy: 0.9843 - val_loss: 0.0959 - val_accuracy: 0.9574\n",
      "Epoch 475/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0538 - accuracy: 0.9843 - val_loss: 0.0968 - val_accuracy: 0.9574\n",
      "Epoch 476/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.0971 - val_accuracy: 0.9574\n",
      "Epoch 477/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.0974 - val_accuracy: 0.9574\n",
      "Epoch 478/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0536 - accuracy: 0.9843 - val_loss: 0.0973 - val_accuracy: 0.9574\n",
      "Epoch 479/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0536 - accuracy: 0.9843 - val_loss: 0.0971 - val_accuracy: 0.9574\n",
      "Epoch 480/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0536 - accuracy: 0.9843 - val_loss: 0.0977 - val_accuracy: 0.9574\n",
      "Epoch 481/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.0978 - val_accuracy: 0.9574\n",
      "Epoch 482/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.0978 - val_accuracy: 0.9574\n",
      "Epoch 483/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.0977 - val_accuracy: 0.9574\n",
      "Epoch 484/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0977 - val_accuracy: 0.9574\n",
      "Epoch 485/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0981 - val_accuracy: 0.9574\n",
      "Epoch 486/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0980 - val_accuracy: 0.9574\n",
      "Epoch 487/500\n",
      "381/381 [==============================] - 0s 249us/sample - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0981 - val_accuracy: 0.9574\n",
      "Epoch 488/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0983 - val_accuracy: 0.9574\n",
      "Epoch 489/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0981 - val_accuracy: 0.9574\n",
      "Epoch 490/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0986 - val_accuracy: 0.9574\n",
      "Epoch 491/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0532 - accuracy: 0.9843 - val_loss: 0.0983 - val_accuracy: 0.9574\n",
      "Epoch 492/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0532 - accuracy: 0.9843 - val_loss: 0.0981 - val_accuracy: 0.9574\n",
      "Epoch 493/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0987 - val_accuracy: 0.9574\n",
      "Epoch 494/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0990 - val_accuracy: 0.9574\n",
      "Epoch 495/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0530 - accuracy: 0.9843 - val_loss: 0.0993 - val_accuracy: 0.9574\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0530 - accuracy: 0.9843 - val_loss: 0.0993 - val_accuracy: 0.9574\n",
      "Epoch 497/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0995 - val_accuracy: 0.9574\n",
      "Epoch 498/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.0996 - val_accuracy: 0.9574\n",
      "Epoch 499/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.0998 - val_accuracy: 0.9574\n",
      "Epoch 500/500\n",
      "381/381 [==============================] - 0s 246us/sample - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.1000 - val_accuracy: 0.9574\n",
      "381/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 82us/sample - loss: 0.0490 - accuracy: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: [0.052799312754722404, 0.984252]\n",
      "188/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 166us/sample - loss: 0.0797 - accuracy: 0.9574\n",
      "Test score: [0.09997307675633024, 0.9574468]\n"
     ]
    }
   ],
   "source": [
    "# Now all the fun Tensorflow stuff\n",
    "# Build the model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Alternatively, you can do:\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n",
    "\n",
    "# Evalute the model - evaluate() returns loass and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x295fa692fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot what's returned by model.fit()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x295fa742a20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3jU1b3v8fd3JgmBgBAgIBAUbEFBIQLx9tgqSqXYqrQKiu3uhaNy7FG31b2r1l60l6f1VLtb+2jlYEutp1pOt8ouuqkXFKR7Vy1BUO5IASUGIVzkIuQyM9/zx/wSh1zIBGaY8Mvn9Tx5Zn7rd1sr6IfFmjXrZ+6OiIiEVyTXFRARkexS0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMi1GfRmNtvMtpvZylb2m5n9ysw2mNnbZjY2Zd8kM1sX7LsrkxUXEZH0WFvz6M3sAmA/8Li7n9HC/s8BtwCfA84BHnT3c8wsCqwHLgEqgSXAte6+uq1K9e3b14cMGdLOpoiIdF5Lly7d4e4lLe3La+tkd19sZkMOc8hkkn8JOPC6mfUyswHAEGCDu28EMLM5wbFtBv2QIUOoqKho6zAREQmY2but7cvEGP0gYEvKdmVQ1lp5i8xshplVmFlFdXV1BqolIiKQmaC3Fsr8MOUtcvdZ7l7u7uUlJS3+60NERI5Am0M3aagEBqdslwJVQEEr5SIicgxlokc/D/hqMPvmXGCPu28l+eHrMDMbamYFwLTgWBEROYba7NGb2R+B8UBfM6sE7gHyAdx9JjCf5IybDcABYHqwL2ZmNwMvAFFgtruvykIbRETkMNKZdXNtG/sduKmVffNJ/kUgIiI5om/GioiEXCY+jBURyZl1H+yjcvcBCvOjvLFxJ5gxsGchVR8ebHbsoOKuvL+7eXmqaCRC3x4FbNtTk60qt6pblzxuvPATGb+ugl7a9MGeGrbtPfb/0XdkETNOG9CDHftrGdCza1buUbn7ADv312Xl2mEy+eH/bnWfpUzyTl0EwFqa/N3O47Khb/cuCno59vYcqOeSX7zKvppYrqvS4Yw5qRfL3vuQB6aWMWVcaUavvXXPQS7++avUxRIZvW7Y/cdN5/PX9dX8/KX1/OG6c/jUsL6N+555s5Lb//QWP7tqNFefNbjVa9z05Jv859tbWfytizipT7djUe2sa3Otm1woLy93LYFw5P7z7a384NlVJDLwR1sXi7O3Jsb9U0bTp3vB0V8wJH7/t3d5dX3yG9xm0KeoS0avX1sf50B9nF9ecyZFXaIZvXbYdMmL0qtbPnWxBGNOKiaRcFZv3csZg3oecpy7s6pqL6cPPAE7TFe9pj7Oll0HGNa/R7arnlFmttTdy1vapx59B/fhgTp+8dJ6atvRs1u0rprC/OghvZmjcWr/Hkwtb70H1Bl9sqQHv/mvjfQuKmD7vtqs3OPM0l5cXjYwK9cOs0jEmoU8gFnL5U0V5kePu5Bvi4L+SOytglh2/udusH1fLeu37ePV9TtYuGpru3rTgy3Cv0wYzrnD+0GP/lmsZed1Up9u/HBys8VcRTokBX17rX8Bnrw667fpF/x8CvhOF6C+nRd4Nni9YSEMGnvYQ0Uk3BT07fWPVyCvK1z2b7S8btvReXntNv7z7a0AXFE2kE/2606/EwopiLbzKw/xOnj2n2HjIgW9SCenoE9XIgF/nwXr5kNpOZz5paO+5KqqPfzipXdIpHwg/sbGYoaXnsXlowfyqfNOJq+9AZ/qtYdgxb9Dtz4w9qvHfq6YiHQICvp0vfc3eP7O5Pvzbm62OxZP8OzbVRyoi6d9yaeWVrL+g32cUtK9sezUE3vw0ytHc+qJGfgwaMQV8NcHkj37k86DkuFHf00ROe4o6NP13mvJ1zs2Qbfeh+xyd37zX5u47y9r233Z735+BNd/+pRM1LC5Cd+D0VfDw2fDltcV9CKdlIL+cPZ9AE9Mgdr98NEOKDmtWcgD/PHvW7jvL2s5Y9AJzP7aWWlfPhIx+hRleW563+HQtTe8+F34678d+XW6FsNX5kLXXpmrW2UF/Mc3IN7eT5rlmCsogi/9P+iZ2S+GybGhoD+cd16CD1Ykh0DyCmHkFS0etmjddgAe/tJY+p1QeCxr2DYzmPjj5IeyR6p2H6z/C2z+K4y4PGNVY9Vc2L0ZRn4hc9eUzIvXwer/SM44O+u6XNdGjoCCvin3ZLjXH4T1zyd7slN/D5FDPxR9b+cB5i57n4Q7b2zaxVVjSzm5T1GOKt2GMV9O/hypWC38dDCseQ6K+mWuXhtfhUHj4KpHM3dNyTx3eGA4vPMi9Nd3B7Iqmpf8fyLDFPRNbXoVHp/88fZplzULeYB75q1k4brkV+CjEWPi6SH+YlJeFxh8Nrw9J/mTSRd8K7PXk8wzgyGfglXPJDs/kj1F/eBb72T8smkFvZlNAh4k+aSo37j7fU32FwOzgU8ANcD/cPeVwb7NwD4gDsRaW4uhw9j0V7AoXDsHIlEYOKbZIWu27mXhumr+5ZLh3DJhWA4qmQNTZif/pZNJFoHB52T2mpIdn/85jPmnXNci/KLZ+cwunUcJRoGHgUtIPgh8iZnNc/fVKYfdDSx39y+a2WnB8RNS9l/k7jsyWO/MiMdg0U/h4K6Pyza8DANGw/CJLZ6y9N3dXPXI3ygqiPLV84Ycm3p2BN37wScntH2chFO33vrzP46l06M/G9jg7hsBzGwOMBlIDfqRwE8B3H2tmQ0xs/7uvi3TFc6o915LzjMv7AXR/I/LR/+vxrfuziOv/oMtuw4AsGTzbgB+NqWMnt3yERHp6NIJ+kHAlpTtSqDpv7ffAq4E/svMzgZOBkqBbYADL5qZA//H3We1dBMzmwHMADjppJPa04Yjt+X15Os/L2tx2uS7Oz9i4drt/Oz5dRR3yyc/GsEM7rtyFJ8fPeDY1FFE5CilE/QtfW++6Urn9wEPmtlyYAWwDGh4UsX57l5lZv2Al8xsrbsvbnbB5F8AsyC5Hn26DWi3Z/4nrAlW/IrVtDo3vqY+ztSZr7F9Xy0lPbrw1zsuojBf64KLyPEnnaCvBFIXIy8FqlIPcPe9wHQAS67ovyn4wd2rgtftZjaX5FBQs6A/JmK1ybnbA8+E0uCLTcMuaXbYvfNW8djfNgPwwNQyLhxeopAXkeNWOkG/BBhmZkOB94FpwCEreplZL+CAu9cB1wOL3X2vmRUBEXffF7yfCPwwoy1oj6rlEK9NrlXTypeftu45yB9ef5dPD+vLpWcM4Kqxgw77NBoRkY6uzaB395iZ3Qy8QHJ65Wx3X2VmNwb7ZwIjgMfNLE7yQ9qGr8/1B+YGQZkHPOnuuZuIW7Us+Vra+jIFC9dWE0s491w+kk/2C9dTZkSkc0prHr27zwfmNymbmfL+NaDZhPJgpk7ZUdYxc/ZsSS5l0OPEFne7OwvWbKNv9wI+kbKipIjI8ewoFjs/Du3ZklyUqZWhmF8v+gevrN3OWUN6a7hGREKjcy2BsOd9OGFQs+IN2/dx59MrWF21l5P7dOM7nx+Rg8qJiGRHJ+vRV0LPwc2Kf7ngHdZs3cunhvXl0a+WU1rcLQeVExHJjs7To4/Vwf5tzdbT3rzjI+av2MoNF5zCty9VT15Ewqfz9Oj3VQEOPQ8dupn1143kRSNcd/7Q3NRLRCTLOk+Pfs/7ydegR//Gxp3c/qe3+GBvDdecNbjjPTBERCRDOlHQVyZfew7mzfd2c/3vK+iSH+Haswdzy8WdZKlhEemUOlHQJ9dlS/QYyF3/t4J9tTHuuaKMKeP0DEwRCbfOEfT7tsErP4LCXizcuJ/12/bzy2vO5Atjmk+1FBEJm87xYWzw+DMffQ2/XvQPSou7cpmWGRaRTqJzBP17r0O3Piw57U6WvrubGRecQl60czRdRKRzpF3VmxzsP47b//0tehcVMHVc8y9NiYiEVacIev9oB4u25lG5+yA3fPoUuhZobXkR6Tw6xYexXrOXzXVR/nXicG688JRcV0dE5JgKf48+VkskUcc+78rkM/UQERHpfMIf9DV7ATgYKWJgr645royIyLGXVtCb2SQzW2dmG8zsrhb2F5vZXDN728z+bmZnpHtu1tUmg75rj2KiEfXmRaTzaTPozSwKPAxcCowErjWzkU0OuxtY7u6jga8CD7bj3Kyq/+hDAHoW9z2WtxUR6TDS6dGfDWxw943Bw7/nAJObHDMSeBnA3dcCQ8ysf5rnZtUbazcDcO5pJx/L24qIdBjpBP0gYEvKdmVQluot4EoAMzsbOBkoTfNcgvNmmFmFmVVUV1enV/s0fLB9GwCjP6m58yLSOaUT9C0NbHuT7fuAYjNbDtwCLANiaZ6bLHSf5e7l7l5eUlKSRrXSc3BfcujGCntm7JoiIseTdObRVwKp3eFSoCr1AHffC0wHsOT8xU3BT7e2zs22mv27k2+6nHAsbysi0mGk06NfAgwzs6FmVgBMA+alHmBmvYJ9ANcDi4Pwb/PcbOtxsJLaSFdQj15EOqk2e/TuHjOzm4EXgCgw291XmdmNwf6ZwAjgcTOLA6uB6w53bnaa0lxtLM7psdVsLz6DwREteyAinVNaSyC4+3xgfpOymSnvXwNafExTS+ceK7t2f8hIe5c1JRPRR7Ei0lmF+puxH+18n6g58V568LeIdF6hDvqaPclpmvndMzeLR0TkeBPqoK/dtwOALj0V9CLSeYU66GP7kz36bgp6EenEQh30/tFOAIp6989xTUREcifUQW8HdhHzCN179M51VUREcibUQR+p2c2H1oOIHgQuIp1YqBOwsHYHe03fiBWRzi28Qe/OwANrqeryiVzXREQkp0Ib9AerN9InsZODA8pzXRURkZwKbdC/u3oJAMXDzs1xTUREciu0Qb9351YASgcPyW1FRERyLLRBXxssf9C35MQc10REJLdCG/Sxj3ZykC7kFXbPdVVERHIqtEFvB3ayP6KplSIioQ36grrd1OQr6EVE0gp6M5tkZuvMbIOZ3dXC/p5m9qyZvWVmq8xsesq+zWa2wsyWm1lFJit/OEXxPdQV9DpWtxMR6bDafMKUmUWBh4FLSD4ofImZzXP31SmH3QSsdvfLzawEWGdmT7h7XbD/InffkenKt8bd6en7OFCgB46IiKTToz8b2ODuG4PgngNMbnKMAz3MzIDuwC4gltGatkNtLEEv9hErLM5VFUREOox0gn4QsCVluzIoS/UQyQeEVwErgFvdPRHsc+BFM1tqZjNau4mZzTCzCjOrqK6uTrsBLTlQU0sv+4h4FwW9iEg6QW8tlHmT7c8Cy4GBwJnAQ2Z2QrDvfHcfC1wK3GRmF7R0E3ef5e7l7l5eUnJ0Dwqp2ZscJfJufY7qOiIiYZBO0FcCg1O2S0n23FNNB57xpA3AJuA0AHevCl63A3NJDgVlVd3e4F8ECnoRkbSCfgkwzMyGmlkBMA2Y1+SY94AJAGbWHzgV2GhmRWbWIygvAiYCKzNV+dbUBc+KjRQp6EVE2px14+4xM7sZeAGIArPdfZWZ3Rjsnwn8CHjMzFaQHOq50913mNkpwNzkZ7TkAU+6+/NZakuj+P5k0Od175vtW4mIdHhtBj2Au88H5jcpm5nyvopkb73peRuBsqOsY7slgmfFKuhFRML6zdgDyaAv7KmgFxEJZ9DX7qXW8+jWTQuaiYiEMui97gA1FNCtS1ojUyIioRbOoK8/SA0FdM2P5roqIiI5F8qgt1gttRQQjbT0XS8Rkc4llEEfjddQS5dcV0NEpEMIbdDXWUGuqyEi0iGEM+gTtdSaevQiIhDSoM+L11KvoBcRAcIa9Ika6jV0IyIChDXovZb6iHr0IiIQ0qDPTyjoRUQahDPovZaYgl5EBAhp0Bck6ogr6EVEgDAGvTtdqCUWLcx1TUREOoS0gt7MJpnZOjPbYGZ3tbC/p5k9a2ZvmdkqM5ue7rkZF6sFIB5R0IuIQBpBb2ZR4GGSD/ceCVxrZiObHHYTsNrdy4DxwM/NrCDNczOr/gAAiTwFvYgIpNejPxvY4O4b3b0OmANMbnKMAz0s+czA7sAuIJbmuZkVqwEgoaEbEREgvaAfBGxJ2a4MylI9BIwAqoAVwK3unkjz3MyqPwgo6EVEGqQT9C2t9etNtj8LLAcGAmcCD5nZCWmem7yJ2QwzqzCziurq6jSq1YqgR+8auhERAdIL+kpgcMp2Kcmee6rpwDOetAHYBJyW5rkAuPssdy939/KSkpJ0699cvYJeRCRVOkG/BBhmZkPNrACYBsxrcsx7wAQAM+sPnApsTPPczIolh25Q0IuIANDmQ1XdPWZmNwMvAFFgtruvMrMbg/0zgR8Bj5nZCpLDNXe6+w6Als7NTlMCQY+e/K5ZvY2IyPEiradnu/t8YH6Tspkp76uAiemem01efyD5wYB69CIiQAi/GRurTc6jp6BbbisiItJBhC7o43XJMfqIhm5ERIAQBn2iLtmjt3wN3YiIQAiDvqFHbwXq0YuIQAiDPhEEfVRj9CIiQAiD3usPUut5FOSnNaFIRCT0Qhf0ibqD1FJAfjR0TRMROSLhS8P6g9RQQIGCXkQECGHQe/1Bajyf/LzQNU1E5IiELw1jBzlIF/KjLS2cKSLS+YQu6K2+hhoK6KIevYgIEMKgJ15LLfn6MFZEJBC+NIzXUe95CnoRkUDo0tAS9cSIUqChGxERIIRBT7yeOvI0vVJEJBC6NLREjBhRDd2IiATSSkMzm2Rm68xsg5nd1cL+b5nZ8uBnpZnFzax3sG+zma0I9lVkugHN6pKop548Dd2IiATaXBDGzKLAw8AlJB/2vcTM5rn76oZj3P1+4P7g+MuB29x9V8plLmp4tGC2RRL11BPVPHoRkUA63d6zgQ3uvtHd64A5wOTDHH8t8MdMVO5IWCJGTLNuREQapZOGg4AtKduVQVkzZtYNmAQ8nVLswItmttTMZrR2EzObYWYVZlZRXV2dRrVauY7HqCeqD2NFRALppGFLYyDeyrGXA//dZNjmfHcfC1wK3GRmF7R0orvPcvdydy8vKSlJo1otiybqiVsekYiGbkREIL2grwQGp2yXAlWtHDuNJsM27l4VvG4H5pIcCsqaiMdImNaiFxFpkE7QLwGGmdlQMysgGebzmh5kZj2BC4E/p5QVmVmPhvfARGBlJiremqjXk4jkZ/MWIiLHlTa7vu4eM7ObgReAKDDb3VeZ2Y3B/pnBoV8EXnT3j1JO7w/MNbOGez3p7s9nsgFNKktUPXoRkUOklYjuPh+Y36RsZpPtx4DHmpRtBMqOqobtkYgn76sevYhIo3BNTYnXAQp6EZFU4Qr6RD0AHtHQjYhIg3AFfTwZ9PowVkTkY6EMeqIKehGRBuEK+mDoBg3diIg0ClfQxxvG6AtyXBERkY4jnEEfVY9eRKRBuIK+cdaNxuhFRBqEK+g1j15EpJmQBX0s+aqgFxFpFLKgD3r0ml4pItIoXEGv6ZUiIs2EK+gbhm6iml4pItIgZEGfHLoxDd2IiDQKV9BreqWISDPhCvpg6CaSp6AXEWmQVtCb2SQzW2dmG8zsrhb2f8vMlgc/K80sbma90zk3oxLJoDd9GCsi0qjNoDezKPAwcCkwErjWzEamHuPu97v7me5+JvBt4FV335XOuRnlySdMmZZAEBFplE6P/mxgg7tvdPc6YA4w+TDHXwv88QjPPTpBjz4SjWbtFiIix5t0gn4QsCVluzIoa8bMugGTgKeP4NwZZlZhZhXV1dVpVKs5TzT06DVGLyLSIJ2gtxbKvJVjLwf+2913tfdcd5/l7uXuXl5SUpJGtZpLBKtXRjVGLyLSKJ2grwQGp2yXAlWtHDuNj4dt2nvuUUvEkz36SJ6CXkSkQTpBvwQYZmZDzayAZJjPa3qQmfUELgT+3N5zMyUR1xi9iEhTbXZ93T1mZjcDLwBRYLa7rzKzG4P9M4NDvwi86O4ftXVuphvRoCHooxqjFxFplNYYh7vPB+Y3KZvZZPsx4LF0zs0Wb/zClIZuREQahOqbsYlg1k0koqEbEZEG4Qr6YNZNnoZuREQahSroPR4n7kY0GqpmiYgclVAlYiIRI0aUvGhL0/dFRDqnUAW9x2MkiJAXCVWzRESOSqgS0ePJHn00oh69iEiDcAV9Ik4CI09BLyLSKHRBrzF6EZFDhSzoNUYvItJUqL5C6ok4cY3Ri4gcIlxd30SMOBHyNXQjItIoVEGf/MJURD16EZEUoQr6j3v04WqWiMjRCFUiumuMXkSkqVAFPfFkj17z6EVEPhauoPd4Mug1dCMi0iitRDSzSWa2zsw2mNldrRwz3syWm9kqM3s1pXyzma0I9lVkquItSsTVoxcRaaLNefRmFgUeBi4h+bDvJWY2z91XpxzTC/g1MMnd3zOzfk0uc5G778hgvVumefQiIs2k06M/G9jg7hvdvQ6YA0xucsyXgGfc/T0Ad9+e2WqmyYMxes2jFxFplE7QDwK2pGxXBmWphgPFZrbIzJaa2VdT9jnwYlA+o7WbmNkMM6sws4rq6up063+oxqEbjdGLiDRIZwmElrrH3sJ1xgETgK7Aa2b2uruvB85396pgOOclM1vr7oubXdB9FjALoLy8vOn102IJfWFKRKSpdLq+lcDglO1SoKqFY55394+CsfjFQBmAu1cFr9uBuSSHgrLDk6tXagkEEZGPpdOjXwIMM7OhwPvANJJj8qn+DDxkZnlAAXAO8AszKwIi7r4veD8R+GHGat+EeZwEeerRi2RQfX09lZWV1NTU5LoqAhQWFlJaWkp+fn7a57QZ9O4eM7ObgReAKDDb3VeZ2Y3B/pnuvsbMngfeBhLAb9x9pZmdAsw1s4Z7Penuz7e7ZelKxIlRQL7G6EUyprKykh49ejBkyBCC/5clR9ydnTt3UllZydChQ9M+L61lit19PjC/SdnMJtv3A/c3KdtIMIRzLEQ8uR59RD16kYypqalRyHcQZkafPn1o74SVcHV9PUHCormuhUjoKOQ7jiP5swhV0Ec8jqOgFxFJFaqgx+Pq0YuINBGqoI94nISFqkkicgzFYrFcVyErQvXMWPM4bqFqkkiH8oNnV7G6am9Grzly4Ancc/npbR73hS98gS1btlBTU8Ott97KjBkzeP7557n77ruJx+P07duXl19+mf3793PLLbdQUVGBmXHPPfdw1VVX0b17d/bv3w/AU089xXPPPcdjjz3G17/+dXr37s2yZcsYO3Ys11xzDd/85jc5ePAgXbt25Xe/+x2nnnoq8XicO++8kxdeeAEz44YbbmDkyJE89NBDzJ07F4CXXnqJRx55hGeeeSajv6OjFapUjHgcV49eJJRmz55N7969OXjwIGeddRaTJ0/mhhtuYPHixQwdOpRdu3YB8KMf/YiePXuyYsUKAHbv3t3mtdevX8+CBQuIRqPs3buXxYsXk5eXx4IFC7j77rt5+umnmTVrFps2bWLZsmXk5eWxa9cuiouLuemmm6iurqakpITf/e53TJ8+Pau/hyMRqqA3zboRyap0et7Z8qtf/aqx57xlyxZmzZrFBRdc0DifvHfv3gAsWLCAOXPmNJ5XXFzc5rWnTp1KNJrMjj179vC1r32Nd955BzOjvr6+8bo33ngjeXl5h9zvK1/5Cn/4wx+YPn06r732Go8//niGWpw5oQr6iMchoqAXCZtFixaxYMECXnvtNbp168b48eMpKytj3bp1zY519xanIKaWNf2Wb1FRUeP7733ve1x00UXMnTuXzZs3M378+MNed/r06Vx++eUUFhYyderUxr8IOpJQjXMYmnUjEkZ79uyhuLiYbt26sXbtWl5//XVqa2t59dVX2bRpE0Dj0M3EiRN56KGHGs9tGLrp378/a9asIZFINP7LoLV7DRqUXKD3scceayyfOHEiM2fObPzAtuF+AwcOZODAgfz4xz/m61//esbanEmhCvqIx0FBLxI6kyZNIhaLMXr0aL73ve9x7rnnUlJSwqxZs7jyyispKyvjmmuuAeC73/0uu3fv5owzzqCsrIyFCxcCcN9993HZZZdx8cUXM2DAgFbvdccdd/Dtb3+b888/n3g83lh+/fXXc9JJJzF69GjKysp48sknG/d9+ctfZvDgwYwcOTJLv4GjY+5HtCJwVpWXl3tFRfufOrj3hyczv+CzTLtrVhZqJdI5rVmzhhEjRuS6Gh3azTffzJgxY7juuuuOyf1a+jMxs6XuXt7S8R1vMOko3FL673x4oI5pua6IiHQa48aNo6ioiJ///Oe5rkqrQhX08YSTFw3VaJSIdHBLly7NdRXaFKpUjCUSWoteRKSJcAV93MlT0IuIHCKtoDezSWa2zsw2mNldrRwz3syWm9kqM3u1PedmSkxDNyIizbQ5Rm9mUeBh4BKSz4ZdYmbz3H11yjG9gF8Dk9z9veBB4Gmdm0nxhHr0IiJNpdP9PRvY4O4b3b0OmANMbnLMl4Bn3P09aHwQeLrnZkx9XGP0IiJNpRP0g4AtKduVQVmq4UCxmS0ys6Vm9tV2nJsx8YSTH1XQi3R23bt3z3UVOpR0ple2lJxNv2WVB4wDJgBdgdfM7PU0z03exGwGMAPgpJNOSqNazcUSTlQPBhfJnr/cBR+syOw1TxwFl96X2Wt2ELFYrEOsfZNOKlYCg1O2S4GqFo553t0/cvcdwGKSDwVP51wA3H2Wu5e7e3lJSUm69T9ELJHQGL1ICN155538+te/bty+9957+cEPfsCECRMYO3Yso0aN4s9//nNa19q/f3+r5z3++OONSxx85StfAWDbtm188YtfpKysjLKyMv72t7+xefNmzjjjjMbzHnjgAe69914Axo8fz913382FF17Igw8+yLPPPss555zDmDFj+MxnPsO2bdsa6zF9+nRGjRrF6NGjefrpp/ntb3/Lbbfd1njdRx99lNtvv/2If2+N3P2wPyR76xuBoUAB8BZwepNjRgAvB8d2A1YCZ6Rzbks/48aN8yNx3k8W+L/+afkRnSsiLVu9enWuq+BvvvmmX3DBBY3bI0aM8Hfffdf37Nnj7u7V1dX+iU98whOJhLu7FxUVtXqt+vr6Fs9buXKlDx8+3Kurq93dfefOne7ufvXVV/svfvELd3ePxWL+4Ycf+qZNm/z0009vvOb999/v9w/9gh0AAAbzSURBVNxzj7u7X3jhhf6Nb3yjcd+uXbsa6/Xoo4/67bff7u7ud9xxh996662HHLd//34/5ZRTvK6uzt3dzzvvPH/77bebtaGlPxOgwlvJ1Db/TeHuMTO7GXgBiAKz3X2Vmd0Y7J/p7mvM7HngbSAB/MbdVwK0dO7R//XUsvqEk6cxepHQGTNmDNu3b6eqqorq6mqKi4sZMGAAt912G4sXLyYSifD++++zbds2TjzxxMNey925++67m533yiuvMGXKFPr27Qt8vN78K6+80rjGfDQapWfPnm0+zKRhgTWAyspKrrnmGrZu3UpdXV3j+vmtrZt/8cUX89xzzzFixAjq6+sZNWpUO39bzaU1eOTu84H5TcpmNtm+H7g/nXOzJZ5wzboRCakpU6bw1FNP8cEHHzBt2jSeeOIJqqurWbp0Kfn5+QwZMqTZOvMtae08b2W9+Zbk5eWRSCQatw+3vv0tt9zC7bffzhVXXMGiRYsah3hau9/111/PT37yE0477bSMPa0qVJ9cxuIJ8vRhrEgoTZs2jTlz5vDUU08xZcoU9uzZQ79+/cjPz2fhwoW8++67aV2ntfMmTJjAn/70J3bu3Al8vN78hAkTeOSRRwCIx+Ps3buX/v37s337dnbu3EltbS3PPffcYe/XsL7973//+8by1tbNP+ecc9iyZQtPPvkk1157bbq/nsMKVSrG9IUpkdA6/fTT2bdvH4MGDWLAgAF8+ctfpqKigvLycp544glOO+20tK7T2nmnn3463/nOd7jwwgspKytr/BD0wQcfZOHChYwaNYpx48axatUq8vPz+f73v88555zDZZdddth733vvvUydOpVPf/rTjcNC0Pq6+QBXX301559/flqPQUxHqNaj/+acZVwwvIQrx5ZmoVYinZPWoz/2LrvsMm677TYmTJjQ4v72rkcfqh79L6eNUciLyHHrww8/ZPjw4XTt2rXVkD8SuZ/JLyKSBStWrGicC9+gS5cuvPHGGzmqUdt69erF+vXrM35dBb2ItKk9M1I6ilGjRrF8+fJcVyPjjmS4PVRDNyKSeYWFhezcufOIAkYyy93ZuXMnhYWF7TpPPXoROazS0lIqKyuprq7OdVWE5F+8paXt+yxSQS8ih5Wfn9/4bU45PmnoRkQk5BT0IiIhp6AXEQm5DvnNWDOrBtJbuKK5vsCODFbneKA2dw5qc+dwpG0+2d1bfJhHhwz6o2FmFa19DTis1ObOQW3uHLLRZg3diIiEnIJeRCTkwhj0s3JdgRxQmzsHtblzyHibQzdGLyIihwpjj15ERFIo6EVEQi40QW9mk8xsnZltMLO7cl2fTDGz2Wa23cxWppT1NrOXzOyd4LU4Zd+3g9/BOjP7bG5qfXTMbLCZLTSzNWa2ysxuDcpD224zKzSzv5vZW0GbfxCUh7bNDcwsambLzOy5YDvUbTazzWa2wsyWm1lFUJbdNrv7cf8DRIF/AKcABcBbwMhc1ytDbbsAGAusTCn7GXBX8P4u4H8H70cGbe8CDA1+J9Fct+EI2jwAGBu87wGsD9oW2nYDBnQP3ucDbwDnhrnNKW2/HXgSeC7YDnWbgc1A3yZlWW1zWHr0ZwMb3H2ju9cBc4DJOa5TRrj7YmBXk+LJQMPj5H8PfCGlfI6717r7JmADyd/NccXdt7r7m8H7fcAaYBAhbrcn7Q8284MfJ8RtBjCzUuDzwG9SikPd5lZktc1hCfpBwJaU7cqgLKz6u/tWSIYi0C8oD93vwcyGAGNI9nBD3e5gCGM5sB14yd1D32bgl8AdQCKlLOxtduBFM1tqZjOCsqy2OSzr0bf0jLPOOG80VL8HM+sOPA180933HuZRdqFot7vHgTPNrBcw18zOOMzhx32bzewyYLu7LzWz8emc0kLZcdXmwPnuXmVm/YCXzGztYY7NSJvD0qOvBAanbJcCVTmqy7GwzcwGAASv24Py0PwezCyfZMg/4e7PBMWhbzeAu38ILAImEe42nw9cYWabSQ63XmxmfyDcbcbdq4LX7cBckkMxWW1zWIJ+CTDMzIaaWQEwDZiX4zpl0zzga8H7rwF/TimfZmZdzGwoMAz4ew7qd1Qs2XX/LbDG3f8tZVdo221mJUFPHjPrCnwGWEuI2+zu33b3UncfQvL/2Vfc/Z8IcZvNrMjMejS8ByYCK8l2m3P9CXQGP8n+HMnZGf8AvpPr+mSwXX8EtgL1JP92vw7oA7wMvBO89k45/jvB72AdcGmu63+Ebf4UyX+evg0sD34+F+Z2A6OBZUGbVwLfD8pD2+Ym7R/Px7NuQttmkjMD3wp+VjVkVbbbrCUQRERCLixDNyIi0goFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5P4/ygDxm7A1kOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy too\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9604645e-07]\n",
      " [9.4769263e-01]\n",
      " [3.3802152e-02]\n",
      " [9.9979824e-01]\n",
      " [9.9890673e-01]\n",
      " [9.9542725e-01]\n",
      " [2.7974248e-03]\n",
      " [9.9904108e-01]\n",
      " [9.9992967e-01]\n",
      " [2.9869890e-01]\n",
      " [6.6064835e-01]\n",
      " [1.0000000e+00]\n",
      " [9.4923806e-01]\n",
      " [9.9999303e-01]\n",
      " [9.9997449e-01]\n",
      " [9.2642725e-01]\n",
      " [9.9997646e-01]\n",
      " [9.9996459e-01]\n",
      " [6.4226985e-04]\n",
      " [9.9992287e-01]\n",
      " [9.9998009e-01]\n",
      " [9.9578619e-01]\n",
      " [9.9993587e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9930525e-01]\n",
      " [9.9987763e-01]\n",
      " [6.0687363e-02]\n",
      " [9.9452937e-01]\n",
      " [9.9013513e-01]\n",
      " [0.0000000e+00]\n",
      " [1.7881393e-07]\n",
      " [9.5681334e-01]\n",
      " [9.9995142e-01]\n",
      " [9.9958694e-01]\n",
      " [9.8046744e-01]\n",
      " [9.1912204e-01]\n",
      " [2.6266518e-01]\n",
      " [9.9993277e-01]\n",
      " [9.9746931e-01]\n",
      " [7.6640618e-01]\n",
      " [7.8444076e-01]\n",
      " [9.9957329e-01]\n",
      " [9.9999952e-01]\n",
      " [8.9096510e-01]\n",
      " [9.7832823e-01]\n",
      " [9.9797988e-01]\n",
      " [8.9946139e-01]\n",
      " [8.9108378e-01]\n",
      " [3.6762875e-01]\n",
      " [9.9909669e-01]\n",
      " [9.8833132e-01]\n",
      " [9.9657828e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9991858e-01]\n",
      " [9.9970770e-01]\n",
      " [2.4735928e-06]\n",
      " [4.0889186e-01]\n",
      " [1.8289387e-03]\n",
      " [8.0873102e-01]\n",
      " [8.8894796e-01]\n",
      " [8.8167942e-01]\n",
      " [9.9998409e-01]\n",
      " [9.9999702e-01]\n",
      " [9.1506690e-01]\n",
      " [0.0000000e+00]\n",
      " [1.0728836e-06]\n",
      " [8.4391314e-01]\n",
      " [1.0728836e-06]\n",
      " [9.9999583e-01]\n",
      " [9.7195363e-01]\n",
      " [0.0000000e+00]\n",
      " [6.6813344e-01]\n",
      " [3.6283672e-02]\n",
      " [9.9539673e-01]\n",
      " [9.9914145e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9966300e-01]\n",
      " [1.3086200e-04]\n",
      " [9.9965495e-01]\n",
      " [0.0000000e+00]\n",
      " [5.0038099e-05]\n",
      " [9.4602013e-01]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [9.9919236e-01]\n",
      " [5.2654445e-03]\n",
      " [8.8481736e-01]\n",
      " [1.4391840e-03]\n",
      " [8.1809831e-01]\n",
      " [9.9995118e-01]\n",
      " [9.9984789e-01]\n",
      " [3.3229589e-05]\n",
      " [6.8813562e-05]\n",
      " [9.0491861e-01]\n",
      " [9.9480909e-01]\n",
      " [9.9687529e-01]\n",
      " [3.2782555e-07]\n",
      " [0.0000000e+00]\n",
      " [8.5857224e-01]\n",
      " [9.9998593e-01]\n",
      " [9.9976027e-01]\n",
      " [2.8508902e-04]\n",
      " [9.9999905e-01]\n",
      " [0.0000000e+00]\n",
      " [3.4327507e-03]\n",
      " [0.0000000e+00]\n",
      " [9.9994838e-01]\n",
      " [9.9512762e-01]\n",
      " [9.9994147e-01]\n",
      " [9.9986029e-01]\n",
      " [1.6905069e-03]\n",
      " [9.9999571e-01]\n",
      " [8.1046200e-01]\n",
      " [8.3856964e-01]\n",
      " [1.1920929e-06]\n",
      " [9.9999714e-01]\n",
      " [2.1725893e-05]\n",
      " [1.7881393e-07]\n",
      " [9.9941880e-01]\n",
      " [9.9956417e-01]\n",
      " [1.2116432e-02]\n",
      " [0.0000000e+00]\n",
      " [9.9925297e-01]\n",
      " [9.9848396e-01]\n",
      " [2.0511627e-02]\n",
      " [9.9288499e-01]\n",
      " [2.9802322e-07]\n",
      " [9.9816394e-01]\n",
      " [3.0636787e-05]\n",
      " [9.9306929e-01]\n",
      " [9.5471889e-01]\n",
      " [3.2331467e-02]\n",
      " [3.5971403e-05]\n",
      " [9.9962968e-01]\n",
      " [4.1850361e-01]\n",
      " [3.5464764e-06]\n",
      " [9.9995065e-01]\n",
      " [9.9998486e-01]\n",
      " [9.6508747e-01]\n",
      " [9.9940228e-01]\n",
      " [1.1530817e-03]\n",
      " [9.7668970e-01]\n",
      " [1.1712313e-05]\n",
      " [9.9992239e-01]\n",
      " [9.8371106e-01]\n",
      " [1.0962635e-02]\n",
      " [1.5344918e-03]\n",
      " [3.2157898e-03]\n",
      " [4.2763859e-02]\n",
      " [9.9999392e-01]\n",
      " [1.0000000e+00]\n",
      " [9.9774015e-01]\n",
      " [5.0663948e-07]\n",
      " [9.9994969e-01]\n",
      " [9.7096729e-01]\n",
      " [2.9802322e-08]\n",
      " [0.0000000e+00]\n",
      " [9.9932617e-01]\n",
      " [9.6401215e-01]\n",
      " [7.7486038e-07]\n",
      " [9.9929088e-01]\n",
      " [9.3454146e-01]\n",
      " [2.3245811e-06]\n",
      " [9.9176085e-01]\n",
      " [1.1622906e-06]\n",
      " [9.9984419e-01]\n",
      " [3.4896910e-02]\n",
      " [9.9781346e-01]\n",
      " [9.9711001e-01]\n",
      " [9.9962807e-01]\n",
      " [9.9987555e-01]\n",
      " [9.9998504e-01]\n",
      " [9.4192755e-01]\n",
      " [4.3791601e-01]\n",
      " [8.0695719e-02]\n",
      " [5.2794147e-01]\n",
      " [9.9997187e-01]\n",
      " [9.6366364e-01]\n",
      " [8.0609620e-03]\n",
      " [9.9545807e-01]\n",
      " [9.9723864e-01]\n",
      " [9.9973679e-01]\n",
      " [9.8171610e-01]\n",
      " [5.9604645e-08]\n",
      " [9.9997330e-01]\n",
      " [9.9900317e-01]\n",
      " [2.2342205e-03]\n",
      " [9.9998295e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "P = model.predict(X_test)\n",
    "print(P) # they are ooutputs of the sigmoid, interpreted as probabilities p(y = 1 | x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
