{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow\n",
    "# direct tensorflow installation throws tensorboard version error on my env\n",
    "# so install tensorboard 2.0.0 first\n",
    "# ! pip install tensorboard==2.0.0\n",
    "# ! pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of 'data'\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: it is a Bunch object\n",
    "# this basically acts like a dictionary where you can treat the keys lie attributes\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'data' (the attribute) means the inout data\n",
    "data.data.shape\n",
    "# it has 569 samples, 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'targets'\n",
    "data.target\n",
    "# note how the targets are just 0s and 1s\n",
    "# normally, when you have K targets, they are labeled 0..K-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their meaning is not lost\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are also 569 corresponding targets\n",
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also determine the meaning of each feature\n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would put all of our imports at the top\n",
    "# but this lets us tell a story\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test sets\n",
    "# this lets us simulate how our model will perform in the future\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# you'll learn why scaling is needed in a later course\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/3-3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/500\n",
      "381/381 [==============================] - 1s 1ms/sample - loss: 1.0919 - accuracy: 0.3307 - val_loss: 0.9948 - val_accuracy: 0.3511\n",
      "Epoch 2/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.9906 - accuracy: 0.3885 - val_loss: 0.8958 - val_accuracy: 0.4415\n",
      "Epoch 3/500\n",
      "381/381 [==============================] - 0s 163us/sample - loss: 0.8973 - accuracy: 0.4567 - val_loss: 0.8065 - val_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.8137 - accuracy: 0.5118 - val_loss: 0.7283 - val_accuracy: 0.5585\n",
      "Epoch 5/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.7413 - accuracy: 0.5696 - val_loss: 0.6592 - val_accuracy: 0.6170\n",
      "Epoch 6/500\n",
      "381/381 [==============================] - 0s 232us/sample - loss: 0.6763 - accuracy: 0.6325 - val_loss: 0.6011 - val_accuracy: 0.7021\n",
      "Epoch 7/500\n",
      "381/381 [==============================] - 0s 158us/sample - loss: 0.6197 - accuracy: 0.6850 - val_loss: 0.5528 - val_accuracy: 0.7500\n",
      "Epoch 8/500\n",
      "381/381 [==============================] - 0s 166us/sample - loss: 0.5737 - accuracy: 0.7244 - val_loss: 0.5104 - val_accuracy: 0.7713\n",
      "Epoch 9/500\n",
      "381/381 [==============================] - 0s 185us/sample - loss: 0.5317 - accuracy: 0.7533 - val_loss: 0.4752 - val_accuracy: 0.8085\n",
      "Epoch 10/500\n",
      "381/381 [==============================] - 0s 212us/sample - loss: 0.4965 - accuracy: 0.7874 - val_loss: 0.4450 - val_accuracy: 0.8351\n",
      "Epoch 11/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.4660 - accuracy: 0.8110 - val_loss: 0.4188 - val_accuracy: 0.8511\n",
      "Epoch 12/500\n",
      "381/381 [==============================] - 0s 216us/sample - loss: 0.4386 - accuracy: 0.8373 - val_loss: 0.3964 - val_accuracy: 0.8617\n",
      "Epoch 13/500\n",
      "381/381 [==============================] - 0s 181us/sample - loss: 0.4157 - accuracy: 0.8504 - val_loss: 0.3763 - val_accuracy: 0.8723\n",
      "Epoch 14/500\n",
      "381/381 [==============================] - 0s 156us/sample - loss: 0.3951 - accuracy: 0.8609 - val_loss: 0.3583 - val_accuracy: 0.8723\n",
      "Epoch 15/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.3766 - accuracy: 0.8714 - val_loss: 0.3423 - val_accuracy: 0.8830\n",
      "Epoch 16/500\n",
      "381/381 [==============================] - 0s 183us/sample - loss: 0.3600 - accuracy: 0.8793 - val_loss: 0.3282 - val_accuracy: 0.8936\n",
      "Epoch 17/500\n",
      "381/381 [==============================] - 0s 191us/sample - loss: 0.3453 - accuracy: 0.8898 - val_loss: 0.3154 - val_accuracy: 0.8989\n",
      "Epoch 18/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.3319 - accuracy: 0.8950 - val_loss: 0.3039 - val_accuracy: 0.8989\n",
      "Epoch 19/500\n",
      "381/381 [==============================] - 0s 280us/sample - loss: 0.3198 - accuracy: 0.9081 - val_loss: 0.2934 - val_accuracy: 0.9043\n",
      "Epoch 20/500\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.3089 - accuracy: 0.9186 - val_loss: 0.2835 - val_accuracy: 0.9043\n",
      "Epoch 21/500\n",
      "381/381 [==============================] - 0s 150us/sample - loss: 0.2985 - accuracy: 0.9318 - val_loss: 0.2746 - val_accuracy: 0.9043\n",
      "Epoch 22/500\n",
      "381/381 [==============================] - 0s 149us/sample - loss: 0.2894 - accuracy: 0.9344 - val_loss: 0.2663 - val_accuracy: 0.9149\n",
      "Epoch 23/500\n",
      "381/381 [==============================] - 0s 214us/sample - loss: 0.2805 - accuracy: 0.9370 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 24/500\n",
      "381/381 [==============================] - 0s 247us/sample - loss: 0.2728 - accuracy: 0.9370 - val_loss: 0.2517 - val_accuracy: 0.9202\n",
      "Epoch 25/500\n",
      "381/381 [==============================] - 0s 266us/sample - loss: 0.2651 - accuracy: 0.9396 - val_loss: 0.2450 - val_accuracy: 0.9202\n",
      "Epoch 26/500\n",
      "381/381 [==============================] - 0s 206us/sample - loss: 0.2581 - accuracy: 0.9449 - val_loss: 0.2390 - val_accuracy: 0.9255\n",
      "Epoch 27/500\n",
      "381/381 [==============================] - 0s 171us/sample - loss: 0.2517 - accuracy: 0.9475 - val_loss: 0.2331 - val_accuracy: 0.9309\n",
      "Epoch 28/500\n",
      "381/381 [==============================] - 0s 249us/sample - loss: 0.2454 - accuracy: 0.9501 - val_loss: 0.2277 - val_accuracy: 0.9309\n",
      "Epoch 29/500\n",
      "381/381 [==============================] - 0s 238us/sample - loss: 0.2398 - accuracy: 0.9528 - val_loss: 0.2226 - val_accuracy: 0.9362\n",
      "Epoch 30/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.2343 - accuracy: 0.9528 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
      "Epoch 31/500\n",
      "381/381 [==============================] - 0s 153us/sample - loss: 0.2291 - accuracy: 0.9528 - val_loss: 0.2132 - val_accuracy: 0.9362\n",
      "Epoch 32/500\n",
      "381/381 [==============================] - 0s 220us/sample - loss: 0.2242 - accuracy: 0.9528 - val_loss: 0.2089 - val_accuracy: 0.9362\n",
      "Epoch 33/500\n",
      "381/381 [==============================] - 0s 255us/sample - loss: 0.2195 - accuracy: 0.9528 - val_loss: 0.2049 - val_accuracy: 0.9415\n",
      "Epoch 34/500\n",
      "381/381 [==============================] - 0s 252us/sample - loss: 0.2152 - accuracy: 0.9554 - val_loss: 0.2010 - val_accuracy: 0.9415\n",
      "Epoch 35/500\n",
      "381/381 [==============================] - 0s 206us/sample - loss: 0.2109 - accuracy: 0.9580 - val_loss: 0.1973 - val_accuracy: 0.9415\n",
      "Epoch 36/500\n",
      "381/381 [==============================] - 0s 160us/sample - loss: 0.2069 - accuracy: 0.9580 - val_loss: 0.1938 - val_accuracy: 0.9415\n",
      "Epoch 37/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.2031 - accuracy: 0.9580 - val_loss: 0.1904 - val_accuracy: 0.9415\n",
      "Epoch 38/500\n",
      "381/381 [==============================] - 0s 160us/sample - loss: 0.1995 - accuracy: 0.9580 - val_loss: 0.1872 - val_accuracy: 0.9415\n",
      "Epoch 39/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1960 - accuracy: 0.9580 - val_loss: 0.1842 - val_accuracy: 0.9415\n",
      "Epoch 40/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.1925 - accuracy: 0.9606 - val_loss: 0.1813 - val_accuracy: 0.9415\n",
      "Epoch 41/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1893 - accuracy: 0.9633 - val_loss: 0.1786 - val_accuracy: 0.9468\n",
      "Epoch 42/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.1862 - accuracy: 0.9633 - val_loss: 0.1759 - val_accuracy: 0.9468\n",
      "Epoch 43/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.1833 - accuracy: 0.9633 - val_loss: 0.1733 - val_accuracy: 0.9468\n",
      "Epoch 44/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1804 - accuracy: 0.9633 - val_loss: 0.1708 - val_accuracy: 0.9521\n",
      "Epoch 45/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1776 - accuracy: 0.9633 - val_loss: 0.1685 - val_accuracy: 0.9574\n",
      "Epoch 46/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.1749 - accuracy: 0.9633 - val_loss: 0.1662 - val_accuracy: 0.9574\n",
      "Epoch 47/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1723 - accuracy: 0.9633 - val_loss: 0.1641 - val_accuracy: 0.9574\n",
      "Epoch 48/500\n",
      "381/381 [==============================] - 0s 144us/sample - loss: 0.1699 - accuracy: 0.9633 - val_loss: 0.1620 - val_accuracy: 0.9574\n",
      "Epoch 49/500\n",
      "381/381 [==============================] - 0s 150us/sample - loss: 0.1675 - accuracy: 0.9633 - val_loss: 0.1599 - val_accuracy: 0.9628\n",
      "Epoch 50/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1651 - accuracy: 0.9633 - val_loss: 0.1581 - val_accuracy: 0.9628\n",
      "Epoch 51/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1630 - accuracy: 0.9633 - val_loss: 0.1562 - val_accuracy: 0.9628\n",
      "Epoch 52/500\n",
      "381/381 [==============================] - 0s 165us/sample - loss: 0.1609 - accuracy: 0.9633 - val_loss: 0.1544 - val_accuracy: 0.9628\n",
      "Epoch 53/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.1586 - accuracy: 0.9659 - val_loss: 0.1527 - val_accuracy: 0.9628\n",
      "Epoch 54/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.1567 - accuracy: 0.9659 - val_loss: 0.1510 - val_accuracy: 0.9628\n",
      "Epoch 55/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.1548 - accuracy: 0.9659 - val_loss: 0.1493 - val_accuracy: 0.9628\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 178us/sample - loss: 0.1528 - accuracy: 0.9659 - val_loss: 0.1478 - val_accuracy: 0.9628\n",
      "Epoch 57/500\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1510 - accuracy: 0.9659 - val_loss: 0.1463 - val_accuracy: 0.9628\n",
      "Epoch 58/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.1492 - accuracy: 0.9659 - val_loss: 0.1448 - val_accuracy: 0.9628\n",
      "Epoch 59/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.1475 - accuracy: 0.9659 - val_loss: 0.1434 - val_accuracy: 0.9628\n",
      "Epoch 60/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.1459 - accuracy: 0.9659 - val_loss: 0.1421 - val_accuracy: 0.9628\n",
      "Epoch 61/500\n",
      "381/381 [==============================] - 0s 157us/sample - loss: 0.1442 - accuracy: 0.9659 - val_loss: 0.1407 - val_accuracy: 0.9628\n",
      "Epoch 62/500\n",
      "381/381 [==============================] - 0s 196us/sample - loss: 0.1426 - accuracy: 0.9659 - val_loss: 0.1395 - val_accuracy: 0.9628\n",
      "Epoch 63/500\n",
      "381/381 [==============================] - 0s 166us/sample - loss: 0.1411 - accuracy: 0.9659 - val_loss: 0.1382 - val_accuracy: 0.9628\n",
      "Epoch 64/500\n",
      "381/381 [==============================] - 0s 186us/sample - loss: 0.1395 - accuracy: 0.9659 - val_loss: 0.1370 - val_accuracy: 0.9628\n",
      "Epoch 65/500\n",
      "381/381 [==============================] - 0s 161us/sample - loss: 0.1382 - accuracy: 0.9659 - val_loss: 0.1358 - val_accuracy: 0.9628\n",
      "Epoch 66/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.1367 - accuracy: 0.9659 - val_loss: 0.1347 - val_accuracy: 0.9628\n",
      "Epoch 67/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1354 - accuracy: 0.9659 - val_loss: 0.1336 - val_accuracy: 0.9628\n",
      "Epoch 68/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.1340 - accuracy: 0.9659 - val_loss: 0.1325 - val_accuracy: 0.9628\n",
      "Epoch 69/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.1328 - accuracy: 0.9659 - val_loss: 0.1315 - val_accuracy: 0.9628\n",
      "Epoch 70/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.1314 - accuracy: 0.9659 - val_loss: 0.1305 - val_accuracy: 0.9628\n",
      "Epoch 71/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.1302 - accuracy: 0.9659 - val_loss: 0.1295 - val_accuracy: 0.9628\n",
      "Epoch 72/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1290 - accuracy: 0.9659 - val_loss: 0.1286 - val_accuracy: 0.9628\n",
      "Epoch 73/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1279 - accuracy: 0.9659 - val_loss: 0.1276 - val_accuracy: 0.9628\n",
      "Epoch 74/500\n",
      "381/381 [==============================] - 0s 151us/sample - loss: 0.1267 - accuracy: 0.9659 - val_loss: 0.1267 - val_accuracy: 0.9628\n",
      "Epoch 75/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.1256 - accuracy: 0.9659 - val_loss: 0.1259 - val_accuracy: 0.9628\n",
      "Epoch 76/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.1245 - accuracy: 0.9685 - val_loss: 0.1250 - val_accuracy: 0.9628\n",
      "Epoch 77/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.1235 - accuracy: 0.9685 - val_loss: 0.1242 - val_accuracy: 0.9681\n",
      "Epoch 78/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.1225 - accuracy: 0.9685 - val_loss: 0.1234 - val_accuracy: 0.9734\n",
      "Epoch 79/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.1214 - accuracy: 0.9685 - val_loss: 0.1226 - val_accuracy: 0.9734\n",
      "Epoch 80/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.1205 - accuracy: 0.9685 - val_loss: 0.1218 - val_accuracy: 0.9734\n",
      "Epoch 81/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.1195 - accuracy: 0.9685 - val_loss: 0.1211 - val_accuracy: 0.9734\n",
      "Epoch 82/500\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.1187 - accuracy: 0.9685 - val_loss: 0.1203 - val_accuracy: 0.9734\n",
      "Epoch 83/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1177 - accuracy: 0.9685 - val_loss: 0.1196 - val_accuracy: 0.9734\n",
      "Epoch 84/500\n",
      "381/381 [==============================] - 0s 148us/sample - loss: 0.1169 - accuracy: 0.9685 - val_loss: 0.1189 - val_accuracy: 0.9734\n",
      "Epoch 85/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1160 - accuracy: 0.9685 - val_loss: 0.1182 - val_accuracy: 0.9734\n",
      "Epoch 86/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.1152 - accuracy: 0.9711 - val_loss: 0.1176 - val_accuracy: 0.9734\n",
      "Epoch 87/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.1143 - accuracy: 0.9738 - val_loss: 0.1170 - val_accuracy: 0.9734\n",
      "Epoch 88/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.1136 - accuracy: 0.9764 - val_loss: 0.1164 - val_accuracy: 0.9734\n",
      "Epoch 89/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1128 - accuracy: 0.9764 - val_loss: 0.1157 - val_accuracy: 0.9734\n",
      "Epoch 90/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.1120 - accuracy: 0.9764 - val_loss: 0.1152 - val_accuracy: 0.9734\n",
      "Epoch 91/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1113 - accuracy: 0.9764 - val_loss: 0.1146 - val_accuracy: 0.9734\n",
      "Epoch 92/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.1105 - accuracy: 0.9764 - val_loss: 0.1140 - val_accuracy: 0.9734\n",
      "Epoch 93/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.1098 - accuracy: 0.9764 - val_loss: 0.1134 - val_accuracy: 0.9734\n",
      "Epoch 94/500\n",
      "381/381 [==============================] - 0s 151us/sample - loss: 0.1091 - accuracy: 0.9764 - val_loss: 0.1129 - val_accuracy: 0.9734\n",
      "Epoch 95/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.1084 - accuracy: 0.9764 - val_loss: 0.1123 - val_accuracy: 0.9734\n",
      "Epoch 96/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.1077 - accuracy: 0.9764 - val_loss: 0.1119 - val_accuracy: 0.9734\n",
      "Epoch 97/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.1071 - accuracy: 0.9764 - val_loss: 0.1114 - val_accuracy: 0.9734\n",
      "Epoch 98/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.1064 - accuracy: 0.9764 - val_loss: 0.1108 - val_accuracy: 0.9734\n",
      "Epoch 99/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.1058 - accuracy: 0.9764 - val_loss: 0.1103 - val_accuracy: 0.9734\n",
      "Epoch 100/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.1051 - accuracy: 0.9764 - val_loss: 0.1099 - val_accuracy: 0.9734\n",
      "Epoch 101/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1046 - accuracy: 0.9764 - val_loss: 0.1094 - val_accuracy: 0.9734\n",
      "Epoch 102/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.1040 - accuracy: 0.9764 - val_loss: 0.1090 - val_accuracy: 0.9734\n",
      "Epoch 103/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.1034 - accuracy: 0.9764 - val_loss: 0.1085 - val_accuracy: 0.9734\n",
      "Epoch 104/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.1028 - accuracy: 0.9764 - val_loss: 0.1081 - val_accuracy: 0.9734\n",
      "Epoch 105/500\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.1022 - accuracy: 0.9764 - val_loss: 0.1077 - val_accuracy: 0.9734\n",
      "Epoch 106/500\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.1017 - accuracy: 0.9764 - val_loss: 0.1072 - val_accuracy: 0.9734\n",
      "Epoch 107/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.1011 - accuracy: 0.9764 - val_loss: 0.1068 - val_accuracy: 0.9734\n",
      "Epoch 108/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.1006 - accuracy: 0.9764 - val_loss: 0.1065 - val_accuracy: 0.9734\n",
      "Epoch 109/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.1001 - accuracy: 0.9764 - val_loss: 0.1061 - val_accuracy: 0.9734\n",
      "Epoch 110/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0996 - accuracy: 0.9764 - val_loss: 0.1057 - val_accuracy: 0.9734\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0991 - accuracy: 0.9764 - val_loss: 0.1053 - val_accuracy: 0.9734\n",
      "Epoch 112/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0986 - accuracy: 0.9764 - val_loss: 0.1049 - val_accuracy: 0.9734\n",
      "Epoch 113/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0981 - accuracy: 0.9764 - val_loss: 0.1046 - val_accuracy: 0.9734\n",
      "Epoch 114/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.1042 - val_accuracy: 0.9734\n",
      "Epoch 115/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0971 - accuracy: 0.9764 - val_loss: 0.1039 - val_accuracy: 0.9734\n",
      "Epoch 116/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0967 - accuracy: 0.9764 - val_loss: 0.1035 - val_accuracy: 0.9787\n",
      "Epoch 117/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0963 - accuracy: 0.9764 - val_loss: 0.1032 - val_accuracy: 0.9787\n",
      "Epoch 118/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0958 - accuracy: 0.9764 - val_loss: 0.1028 - val_accuracy: 0.9787\n",
      "Epoch 119/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0954 - accuracy: 0.9764 - val_loss: 0.1025 - val_accuracy: 0.9787\n",
      "Epoch 120/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0949 - accuracy: 0.9764 - val_loss: 0.1022 - val_accuracy: 0.9787\n",
      "Epoch 121/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0945 - accuracy: 0.9764 - val_loss: 0.1019 - val_accuracy: 0.9787\n",
      "Epoch 122/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0941 - accuracy: 0.9764 - val_loss: 0.1016 - val_accuracy: 0.9787\n",
      "Epoch 123/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0937 - accuracy: 0.9764 - val_loss: 0.1013 - val_accuracy: 0.9787\n",
      "Epoch 124/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0933 - accuracy: 0.9764 - val_loss: 0.1010 - val_accuracy: 0.9787\n",
      "Epoch 125/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0929 - accuracy: 0.9764 - val_loss: 0.1007 - val_accuracy: 0.9787\n",
      "Epoch 126/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0925 - accuracy: 0.9764 - val_loss: 0.1004 - val_accuracy: 0.9787\n",
      "Epoch 127/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0921 - accuracy: 0.9764 - val_loss: 0.1001 - val_accuracy: 0.9787\n",
      "Epoch 128/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0917 - accuracy: 0.9764 - val_loss: 0.0999 - val_accuracy: 0.9787\n",
      "Epoch 129/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0913 - accuracy: 0.9764 - val_loss: 0.0996 - val_accuracy: 0.9840\n",
      "Epoch 130/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0910 - accuracy: 0.9764 - val_loss: 0.0993 - val_accuracy: 0.9840\n",
      "Epoch 131/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0906 - accuracy: 0.9764 - val_loss: 0.0991 - val_accuracy: 0.9840\n",
      "Epoch 132/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0903 - accuracy: 0.9764 - val_loss: 0.0988 - val_accuracy: 0.9840\n",
      "Epoch 133/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0899 - accuracy: 0.9764 - val_loss: 0.0986 - val_accuracy: 0.9840\n",
      "Epoch 134/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0896 - accuracy: 0.9764 - val_loss: 0.0983 - val_accuracy: 0.9840\n",
      "Epoch 135/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0892 - accuracy: 0.9764 - val_loss: 0.0981 - val_accuracy: 0.9840\n",
      "Epoch 136/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0889 - accuracy: 0.9764 - val_loss: 0.0978 - val_accuracy: 0.9840\n",
      "Epoch 137/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0886 - accuracy: 0.9764 - val_loss: 0.0976 - val_accuracy: 0.9840\n",
      "Epoch 138/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0882 - accuracy: 0.9764 - val_loss: 0.0973 - val_accuracy: 0.9840\n",
      "Epoch 139/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0879 - accuracy: 0.9764 - val_loss: 0.0971 - val_accuracy: 0.9840\n",
      "Epoch 140/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0876 - accuracy: 0.9764 - val_loss: 0.0969 - val_accuracy: 0.9840\n",
      "Epoch 141/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0873 - accuracy: 0.9764 - val_loss: 0.0967 - val_accuracy: 0.9840\n",
      "Epoch 142/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0870 - accuracy: 0.9764 - val_loss: 0.0965 - val_accuracy: 0.9840\n",
      "Epoch 143/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0867 - accuracy: 0.9764 - val_loss: 0.0962 - val_accuracy: 0.9840\n",
      "Epoch 144/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.0864 - accuracy: 0.9764 - val_loss: 0.0960 - val_accuracy: 0.9840\n",
      "Epoch 145/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.0861 - accuracy: 0.9764 - val_loss: 0.0958 - val_accuracy: 0.9840\n",
      "Epoch 146/500\n",
      "381/381 [==============================] - 0s 210us/sample - loss: 0.0858 - accuracy: 0.9764 - val_loss: 0.0956 - val_accuracy: 0.9840\n",
      "Epoch 147/500\n",
      "381/381 [==============================] - 0s 160us/sample - loss: 0.0855 - accuracy: 0.9790 - val_loss: 0.0953 - val_accuracy: 0.9840\n",
      "Epoch 148/500\n",
      "381/381 [==============================] - 0s 155us/sample - loss: 0.0852 - accuracy: 0.9790 - val_loss: 0.0951 - val_accuracy: 0.9840\n",
      "Epoch 149/500\n",
      "381/381 [==============================] - 0s 148us/sample - loss: 0.0849 - accuracy: 0.9790 - val_loss: 0.0950 - val_accuracy: 0.9840\n",
      "Epoch 150/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0846 - accuracy: 0.9790 - val_loss: 0.0948 - val_accuracy: 0.9840\n",
      "Epoch 151/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0843 - accuracy: 0.9790 - val_loss: 0.0946 - val_accuracy: 0.9840\n",
      "Epoch 152/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0841 - accuracy: 0.9790 - val_loss: 0.0944 - val_accuracy: 0.9840\n",
      "Epoch 153/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0838 - accuracy: 0.9790 - val_loss: 0.0942 - val_accuracy: 0.9840\n",
      "Epoch 154/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0836 - accuracy: 0.9790 - val_loss: 0.0941 - val_accuracy: 0.9840\n",
      "Epoch 155/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0833 - accuracy: 0.9790 - val_loss: 0.0939 - val_accuracy: 0.9840\n",
      "Epoch 156/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0830 - accuracy: 0.9790 - val_loss: 0.0937 - val_accuracy: 0.9840\n",
      "Epoch 157/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0828 - accuracy: 0.9790 - val_loss: 0.0935 - val_accuracy: 0.9840\n",
      "Epoch 158/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0825 - accuracy: 0.9790 - val_loss: 0.0934 - val_accuracy: 0.9840\n",
      "Epoch 159/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0823 - accuracy: 0.9790 - val_loss: 0.0932 - val_accuracy: 0.9840\n",
      "Epoch 160/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0820 - accuracy: 0.9790 - val_loss: 0.0930 - val_accuracy: 0.9840\n",
      "Epoch 161/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0818 - accuracy: 0.9790 - val_loss: 0.0928 - val_accuracy: 0.9840\n",
      "Epoch 162/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0815 - accuracy: 0.9790 - val_loss: 0.0927 - val_accuracy: 0.9840\n",
      "Epoch 163/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0813 - accuracy: 0.9790 - val_loss: 0.0925 - val_accuracy: 0.9840\n",
      "Epoch 164/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0811 - accuracy: 0.9790 - val_loss: 0.0924 - val_accuracy: 0.9840\n",
      "Epoch 165/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0808 - accuracy: 0.9790 - val_loss: 0.0922 - val_accuracy: 0.9840\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0806 - accuracy: 0.9790 - val_loss: 0.0921 - val_accuracy: 0.9840\n",
      "Epoch 167/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0804 - accuracy: 0.9790 - val_loss: 0.0919 - val_accuracy: 0.9840\n",
      "Epoch 168/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0801 - accuracy: 0.9790 - val_loss: 0.0917 - val_accuracy: 0.9840\n",
      "Epoch 169/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0799 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9840\n",
      "Epoch 170/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0797 - accuracy: 0.9790 - val_loss: 0.0915 - val_accuracy: 0.9840\n",
      "Epoch 171/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0795 - accuracy: 0.9790 - val_loss: 0.0913 - val_accuracy: 0.9840\n",
      "Epoch 172/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0792 - accuracy: 0.9790 - val_loss: 0.0912 - val_accuracy: 0.9840\n",
      "Epoch 173/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0790 - accuracy: 0.9790 - val_loss: 0.0910 - val_accuracy: 0.9840\n",
      "Epoch 174/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0788 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9840\n",
      "Epoch 175/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0786 - accuracy: 0.9790 - val_loss: 0.0908 - val_accuracy: 0.9840\n",
      "Epoch 176/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0784 - accuracy: 0.9790 - val_loss: 0.0906 - val_accuracy: 0.9840\n",
      "Epoch 177/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0782 - accuracy: 0.9790 - val_loss: 0.0905 - val_accuracy: 0.9840\n",
      "Epoch 178/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0780 - accuracy: 0.9790 - val_loss: 0.0904 - val_accuracy: 0.9840\n",
      "Epoch 179/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0778 - accuracy: 0.9790 - val_loss: 0.0902 - val_accuracy: 0.9840\n",
      "Epoch 180/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0776 - accuracy: 0.9790 - val_loss: 0.0900 - val_accuracy: 0.9840\n",
      "Epoch 181/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0774 - accuracy: 0.9790 - val_loss: 0.0899 - val_accuracy: 0.9840\n",
      "Epoch 182/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0772 - accuracy: 0.9790 - val_loss: 0.0898 - val_accuracy: 0.9840\n",
      "Epoch 183/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0770 - accuracy: 0.9790 - val_loss: 0.0897 - val_accuracy: 0.9840\n",
      "Epoch 184/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0896 - val_accuracy: 0.9840\n",
      "Epoch 185/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0766 - accuracy: 0.9790 - val_loss: 0.0894 - val_accuracy: 0.9840\n",
      "Epoch 186/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0764 - accuracy: 0.9790 - val_loss: 0.0893 - val_accuracy: 0.9840\n",
      "Epoch 187/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0762 - accuracy: 0.9790 - val_loss: 0.0892 - val_accuracy: 0.9840\n",
      "Epoch 188/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0761 - accuracy: 0.9790 - val_loss: 0.0891 - val_accuracy: 0.9840\n",
      "Epoch 189/500\n",
      "381/381 [==============================] - 0s 148us/sample - loss: 0.0759 - accuracy: 0.9790 - val_loss: 0.0890 - val_accuracy: 0.9840\n",
      "Epoch 190/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0757 - accuracy: 0.9790 - val_loss: 0.0889 - val_accuracy: 0.9840\n",
      "Epoch 191/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0755 - accuracy: 0.9790 - val_loss: 0.0888 - val_accuracy: 0.9840\n",
      "Epoch 192/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0753 - accuracy: 0.9790 - val_loss: 0.0887 - val_accuracy: 0.9840\n",
      "Epoch 193/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0752 - accuracy: 0.9790 - val_loss: 0.0885 - val_accuracy: 0.9840\n",
      "Epoch 194/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0750 - accuracy: 0.9790 - val_loss: 0.0884 - val_accuracy: 0.9840\n",
      "Epoch 195/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.0748 - accuracy: 0.9790 - val_loss: 0.0883 - val_accuracy: 0.9840\n",
      "Epoch 196/500\n",
      "381/381 [==============================] - 0s 147us/sample - loss: 0.0746 - accuracy: 0.9790 - val_loss: 0.0882 - val_accuracy: 0.9840\n",
      "Epoch 197/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0745 - accuracy: 0.9790 - val_loss: 0.0881 - val_accuracy: 0.9840\n",
      "Epoch 198/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0743 - accuracy: 0.9790 - val_loss: 0.0880 - val_accuracy: 0.9840\n",
      "Epoch 199/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0741 - accuracy: 0.9790 - val_loss: 0.0879 - val_accuracy: 0.9840\n",
      "Epoch 200/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0740 - accuracy: 0.9790 - val_loss: 0.0878 - val_accuracy: 0.9840\n",
      "Epoch 201/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0738 - accuracy: 0.9790 - val_loss: 0.0877 - val_accuracy: 0.9840\n",
      "Epoch 202/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0736 - accuracy: 0.9790 - val_loss: 0.0876 - val_accuracy: 0.9840\n",
      "Epoch 203/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0735 - accuracy: 0.9790 - val_loss: 0.0875 - val_accuracy: 0.9840\n",
      "Epoch 204/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0733 - accuracy: 0.9790 - val_loss: 0.0874 - val_accuracy: 0.9840\n",
      "Epoch 205/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0731 - accuracy: 0.9790 - val_loss: 0.0873 - val_accuracy: 0.9840\n",
      "Epoch 206/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0730 - accuracy: 0.9790 - val_loss: 0.0872 - val_accuracy: 0.9840\n",
      "Epoch 207/500\n",
      "381/381 [==============================] - 0s 160us/sample - loss: 0.0728 - accuracy: 0.9790 - val_loss: 0.0871 - val_accuracy: 0.9840\n",
      "Epoch 208/500\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.0727 - accuracy: 0.9790 - val_loss: 0.0870 - val_accuracy: 0.9840\n",
      "Epoch 209/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0725 - accuracy: 0.9790 - val_loss: 0.0869 - val_accuracy: 0.9840\n",
      "Epoch 210/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0724 - accuracy: 0.9790 - val_loss: 0.0868 - val_accuracy: 0.9840\n",
      "Epoch 211/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0722 - accuracy: 0.9790 - val_loss: 0.0868 - val_accuracy: 0.9840\n",
      "Epoch 212/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0721 - accuracy: 0.9790 - val_loss: 0.0867 - val_accuracy: 0.9840\n",
      "Epoch 213/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0719 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9840\n",
      "Epoch 214/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0718 - accuracy: 0.9790 - val_loss: 0.0865 - val_accuracy: 0.9840\n",
      "Epoch 215/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0716 - accuracy: 0.9790 - val_loss: 0.0864 - val_accuracy: 0.9840\n",
      "Epoch 216/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0715 - accuracy: 0.9790 - val_loss: 0.0864 - val_accuracy: 0.9840\n",
      "Epoch 217/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0713 - accuracy: 0.9790 - val_loss: 0.0863 - val_accuracy: 0.9840\n",
      "Epoch 218/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0712 - accuracy: 0.9790 - val_loss: 0.0862 - val_accuracy: 0.9840\n",
      "Epoch 219/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0710 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9840\n",
      "Epoch 220/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0709 - accuracy: 0.9790 - val_loss: 0.0860 - val_accuracy: 0.9840\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0707 - accuracy: 0.9790 - val_loss: 0.0860 - val_accuracy: 0.9840\n",
      "Epoch 222/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0706 - accuracy: 0.9790 - val_loss: 0.0859 - val_accuracy: 0.9840\n",
      "Epoch 223/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0704 - accuracy: 0.9790 - val_loss: 0.0858 - val_accuracy: 0.9840\n",
      "Epoch 224/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.0857 - val_accuracy: 0.9840\n",
      "Epoch 225/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.0857 - val_accuracy: 0.9840\n",
      "Epoch 226/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0701 - accuracy: 0.9790 - val_loss: 0.0856 - val_accuracy: 0.9840\n",
      "Epoch 227/500\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0855 - val_accuracy: 0.9840\n",
      "Epoch 228/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0698 - accuracy: 0.9790 - val_loss: 0.0854 - val_accuracy: 0.9840\n",
      "Epoch 229/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0696 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9840\n",
      "Epoch 230/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9840\n",
      "Epoch 231/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0694 - accuracy: 0.9790 - val_loss: 0.0852 - val_accuracy: 0.9840\n",
      "Epoch 232/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0693 - accuracy: 0.9790 - val_loss: 0.0851 - val_accuracy: 0.9840\n",
      "Epoch 233/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0691 - accuracy: 0.9790 - val_loss: 0.0850 - val_accuracy: 0.9840\n",
      "Epoch 234/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0690 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9840\n",
      "Epoch 235/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0689 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9840\n",
      "Epoch 236/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9840\n",
      "Epoch 237/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0686 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9840\n",
      "Epoch 238/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0685 - accuracy: 0.9790 - val_loss: 0.0847 - val_accuracy: 0.9840\n",
      "Epoch 239/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.0846 - val_accuracy: 0.9840\n",
      "Epoch 240/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.0846 - val_accuracy: 0.9840\n",
      "Epoch 241/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0681 - accuracy: 0.9790 - val_loss: 0.0845 - val_accuracy: 0.9840\n",
      "Epoch 242/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.0845 - val_accuracy: 0.9840\n",
      "Epoch 243/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0679 - accuracy: 0.9790 - val_loss: 0.0844 - val_accuracy: 0.9840\n",
      "Epoch 244/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0677 - accuracy: 0.9790 - val_loss: 0.0843 - val_accuracy: 0.9840\n",
      "Epoch 245/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0676 - accuracy: 0.9790 - val_loss: 0.0843 - val_accuracy: 0.9840\n",
      "Epoch 246/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.0842 - val_accuracy: 0.9840\n",
      "Epoch 247/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0674 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9840\n",
      "Epoch 248/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9840\n",
      "Epoch 249/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9840\n",
      "Epoch 250/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.0840 - val_accuracy: 0.9840\n",
      "Epoch 251/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.0839 - val_accuracy: 0.9840\n",
      "Epoch 252/500\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0839 - val_accuracy: 0.9840\n",
      "Epoch 253/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.0667 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9840\n",
      "Epoch 254/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0666 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9840\n",
      "Epoch 255/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.0665 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9840\n",
      "Epoch 256/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0664 - accuracy: 0.9790 - val_loss: 0.0837 - val_accuracy: 0.9840\n",
      "Epoch 257/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0662 - accuracy: 0.9790 - val_loss: 0.0835 - val_accuracy: 0.9840\n",
      "Epoch 258/500\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0835 - val_accuracy: 0.9840\n",
      "Epoch 259/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0660 - accuracy: 0.9790 - val_loss: 0.0835 - val_accuracy: 0.9840\n",
      "Epoch 260/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0659 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9840\n",
      "Epoch 261/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9840\n",
      "Epoch 262/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0657 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9840\n",
      "Epoch 263/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0656 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9840\n",
      "Epoch 264/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.0833 - val_accuracy: 0.9840\n",
      "Epoch 265/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0654 - accuracy: 0.9790 - val_loss: 0.0832 - val_accuracy: 0.9840\n",
      "Epoch 266/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0653 - accuracy: 0.9790 - val_loss: 0.0832 - val_accuracy: 0.9840\n",
      "Epoch 267/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 268/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0650 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 269/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 270/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0648 - accuracy: 0.9790 - val_loss: 0.0830 - val_accuracy: 0.9840\n",
      "Epoch 271/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9840\n",
      "Epoch 272/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9840\n",
      "Epoch 273/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9840\n",
      "Epoch 274/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0644 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9840\n",
      "Epoch 275/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0643 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9840\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9840\n",
      "Epoch 277/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9894\n",
      "Epoch 278/500\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9894\n",
      "Epoch 279/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0639 - accuracy: 0.9790 - val_loss: 0.0826 - val_accuracy: 0.9894\n",
      "Epoch 280/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.0826 - val_accuracy: 0.9894\n",
      "Epoch 281/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0825 - val_accuracy: 0.9894\n",
      "Epoch 282/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0825 - val_accuracy: 0.9894\n",
      "Epoch 283/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9894\n",
      "Epoch 284/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9894\n",
      "Epoch 285/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.0823 - val_accuracy: 0.9894\n",
      "Epoch 286/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9894\n",
      "Epoch 287/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0823 - val_accuracy: 0.9894\n",
      "Epoch 288/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0823 - val_accuracy: 0.9894\n",
      "Epoch 289/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.0823 - val_accuracy: 0.9894\n",
      "Epoch 290/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0629 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9894\n",
      "Epoch 291/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0628 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9894\n",
      "Epoch 292/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9894\n",
      "Epoch 293/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0626 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9894\n",
      "Epoch 294/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0625 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9894\n",
      "Epoch 295/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0624 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9894\n",
      "Epoch 296/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0623 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9894\n",
      "Epoch 297/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.0820 - val_accuracy: 0.9894\n",
      "Epoch 298/500\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.0621 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 299/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0620 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 300/500\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 301/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 302/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9894\n",
      "Epoch 303/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0617 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9894\n",
      "Epoch 304/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0616 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 305/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0615 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 306/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0614 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 307/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0613 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 308/500\n",
      "381/381 [==============================] - 0s 186us/sample - loss: 0.0613 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 309/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0612 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 310/500\n",
      "381/381 [==============================] - 0s 112us/sample - loss: 0.0611 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 311/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0610 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 312/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0609 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 313/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0608 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 314/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0607 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 315/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0607 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 316/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 317/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0605 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 318/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 319/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 320/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 321/500\n",
      "381/381 [==============================] - 0s 128us/sample - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 322/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0601 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 323/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0600 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 324/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0599 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 325/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0598 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 326/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0598 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 327/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0597 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 328/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0596 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 329/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0596 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 330/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0595 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0594 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 332/500\n",
      "381/381 [==============================] - 0s 155us/sample - loss: 0.0593 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 333/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 334/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 335/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0591 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 336/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 337/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 338/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 339/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0588 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 340/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0587 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 341/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0587 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 342/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0586 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 343/500\n",
      "381/381 [==============================] - 0s 114us/sample - loss: 0.0585 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 344/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0584 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 345/500\n",
      "381/381 [==============================] - 0s 121us/sample - loss: 0.0584 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 346/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0583 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 347/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0582 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 348/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 349/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 350/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0580 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 351/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 352/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 353/500\n",
      "381/381 [==============================] - 0s 117us/sample - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 354/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0577 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 355/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 356/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 357/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 358/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 359/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 360/500\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.0573 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 361/500\n",
      "381/381 [==============================] - 0s 118us/sample - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 362/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 363/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 364/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 365/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 366/500\n",
      "381/381 [==============================] - 0s 161us/sample - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 367/500\n",
      "381/381 [==============================] - 0s 171us/sample - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 368/500\n",
      "381/381 [==============================] - 0s 218us/sample - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 369/500\n",
      "381/381 [==============================] - 0s 177us/sample - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 370/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 371/500\n",
      "381/381 [==============================] - 0s 203us/sample - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 372/500\n",
      "381/381 [==============================] - 0s 174us/sample - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 373/500\n",
      "381/381 [==============================] - 0s 178us/sample - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 374/500\n",
      "381/381 [==============================] - 0s 178us/sample - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 375/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 376/500\n",
      "381/381 [==============================] - 0s 182us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9894\n",
      "Epoch 377/500\n",
      "381/381 [==============================] - 0s 178us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 378/500\n",
      "381/381 [==============================] - 0s 190us/sample - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 379/500\n",
      "381/381 [==============================] - 0s 176us/sample - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 380/500\n",
      "381/381 [==============================] - 0s 200us/sample - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 381/500\n",
      "381/381 [==============================] - 0s 210us/sample - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 382/500\n",
      "381/381 [==============================] - 0s 186us/sample - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 383/500\n",
      "381/381 [==============================] - 0s 167us/sample - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 384/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 385/500\n",
      "381/381 [==============================] - 0s 190us/sample - loss: 0.0557 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 175us/sample - loss: 0.0557 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 387/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.0556 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 388/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.0555 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 389/500\n",
      "381/381 [==============================] - 0s 195us/sample - loss: 0.0555 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9894\n",
      "Epoch 390/500\n",
      "381/381 [==============================] - 0s 180us/sample - loss: 0.0554 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9894\n",
      "Epoch 391/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.0553 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9894\n",
      "Epoch 392/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.0553 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9894\n",
      "Epoch 393/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 1.00 - 0s 170us/sample - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 394/500\n",
      "381/381 [==============================] - 0s 174us/sample - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 395/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 396/500\n",
      "381/381 [==============================] - 0s 202us/sample - loss: 0.0550 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 397/500\n",
      "381/381 [==============================] - 0s 210us/sample - loss: 0.0550 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 398/500\n",
      "381/381 [==============================] - 0s 166us/sample - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 399/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 400/500\n",
      "381/381 [==============================] - 0s 183us/sample - loss: 0.0548 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 401/500\n",
      "381/381 [==============================] - 0s 175us/sample - loss: 0.0548 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 402/500\n",
      "381/381 [==============================] - 0s 175us/sample - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 403/500\n",
      "381/381 [==============================] - 0s 170us/sample - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9894\n",
      "Epoch 404/500\n",
      "381/381 [==============================] - 0s 218us/sample - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 405/500\n",
      "381/381 [==============================] - 0s 188us/sample - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 406/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 407/500\n",
      "381/381 [==============================] - 0s 178us/sample - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 408/500\n",
      "381/381 [==============================] - 0s 188us/sample - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 409/500\n",
      "381/381 [==============================] - 0s 173us/sample - loss: 0.0543 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 410/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0543 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 411/500\n",
      "381/381 [==============================] - 0s 220us/sample - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 412/500\n",
      "381/381 [==============================] - 0s 178us/sample - loss: 0.0541 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 413/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.0541 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 414/500\n",
      "381/381 [==============================] - 0s 169us/sample - loss: 0.0540 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 415/500\n",
      "381/381 [==============================] - 0s 180us/sample - loss: 0.0540 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 416/500\n",
      "381/381 [==============================] - 0s 171us/sample - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 417/500\n",
      "381/381 [==============================] - 0s 166us/sample - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 418/500\n",
      "381/381 [==============================] - 0s 209us/sample - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 419/500\n",
      "381/381 [==============================] - 0s 195us/sample - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 420/500\n",
      "381/381 [==============================] - 0s 171us/sample - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9894\n",
      "Epoch 421/500\n",
      "381/381 [==============================] - 0s 186us/sample - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 422/500\n",
      "381/381 [==============================] - 0s 155us/sample - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 423/500\n",
      "381/381 [==============================] - 0s 162us/sample - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 424/500\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 425/500\n",
      "381/381 [==============================] - 0s 158us/sample - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 426/500\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 427/500\n",
      "381/381 [==============================] - 0s 157us/sample - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 428/500\n",
      "381/381 [==============================] - 0s 129us/sample - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 429/500\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9894\n",
      "Epoch 430/500\n",
      "381/381 [==============================] - 0s 158us/sample - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 431/500\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 432/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 433/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 434/500\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 435/500\n",
      "381/381 [==============================] - 0s 187us/sample - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 436/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9894\n",
      "Epoch 437/500\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 438/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 439/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 440/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.0812 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 442/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 443/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 444/500\n",
      "381/381 [==============================] - 0s 152us/sample - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 445/500\n",
      "381/381 [==============================] - 0s 126us/sample - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 446/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0524 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 447/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 448/500\n",
      "381/381 [==============================] - 0s 148us/sample - loss: 0.0523 - accuracy: 0.9843 - val_loss: 0.0812 - val_accuracy: 0.9894\n",
      "Epoch 449/500\n",
      "381/381 [==============================] - 0s 119us/sample - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 450/500\n",
      "381/381 [==============================] - 0s 111us/sample - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.0813 - val_accuracy: 0.9894\n",
      "Epoch 451/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0522 - accuracy: 0.9816 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 452/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 453/500\n",
      "381/381 [==============================] - 0s 154us/sample - loss: 0.0521 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 454/500\n",
      "381/381 [==============================] - 0s 160us/sample - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 455/500\n",
      "381/381 [==============================] - 0s 147us/sample - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 456/500\n",
      "381/381 [==============================] - 0s 149us/sample - loss: 0.0519 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 457/500\n",
      "381/381 [==============================] - 0s 149us/sample - loss: 0.0519 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 458/500\n",
      "381/381 [==============================] - 0s 150us/sample - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 459/500\n",
      "381/381 [==============================] - 0s 150us/sample - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9894\n",
      "Epoch 460/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 461/500\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.0815 - val_accuracy: 0.9894\n",
      "Epoch 462/500\n",
      "381/381 [==============================] - 0s 165us/sample - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 463/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 464/500\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 465/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 466/500\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 467/500\n",
      "381/381 [==============================] - 0s 144us/sample - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 468/500\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0816 - val_accuracy: 0.9894\n",
      "Epoch 469/500\n",
      "381/381 [==============================] - 0s 120us/sample - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 470/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 471/500\n",
      "381/381 [==============================] - 0s 155us/sample - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.0818 - val_accuracy: 0.9894\n",
      "Epoch 472/500\n",
      "381/381 [==============================] - 0s 116us/sample - loss: 0.0512 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 473/500\n",
      "381/381 [==============================] - 0s 113us/sample - loss: 0.0512 - accuracy: 0.9843 - val_loss: 0.0818 - val_accuracy: 0.9894\n",
      "Epoch 474/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0511 - accuracy: 0.9843 - val_loss: 0.0817 - val_accuracy: 0.9894\n",
      "Epoch 475/500\n",
      "381/381 [==============================] - 0s 198us/sample - loss: 0.0511 - accuracy: 0.9843 - val_loss: 0.0818 - val_accuracy: 0.9894\n",
      "Epoch 476/500\n",
      "381/381 [==============================] - 0s 208us/sample - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 477/500\n",
      "381/381 [==============================] - 0s 187us/sample - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 478/500\n",
      "381/381 [==============================] - 0s 164us/sample - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0820 - val_accuracy: 0.9840\n",
      "Epoch 479/500\n",
      "381/381 [==============================] - 0s 205us/sample - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 480/500\n",
      "381/381 [==============================] - 0s 165us/sample - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.0819 - val_accuracy: 0.9894\n",
      "Epoch 481/500\n",
      "381/381 [==============================] - 0s 163us/sample - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0820 - val_accuracy: 0.9894\n",
      "Epoch 482/500\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0820 - val_accuracy: 0.9894\n",
      "Epoch 483/500\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0820 - val_accuracy: 0.9840\n",
      "Epoch 484/500\n",
      "381/381 [==============================] - 0s 122us/sample - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.0822 - val_accuracy: 0.9840\n",
      "Epoch 485/500\n",
      "381/381 [==============================] - 0s 124us/sample - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0821 - val_accuracy: 0.9840\n",
      "Epoch 486/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0821 - val_accuracy: 0.9840\n",
      "Epoch 487/500\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0822 - val_accuracy: 0.9840\n",
      "Epoch 488/500\n",
      "381/381 [==============================] - 0s 147us/sample - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0822 - val_accuracy: 0.9840\n",
      "Epoch 489/500\n",
      "381/381 [==============================] - 0s 172us/sample - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 490/500\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0822 - val_accuracy: 0.9840\n",
      "Epoch 491/500\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.0822 - val_accuracy: 0.9894\n",
      "Epoch 492/500\n",
      "381/381 [==============================] - 0s 125us/sample - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 493/500\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 494/500\n",
      "381/381 [==============================] - 0s 123us/sample - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 495/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0824 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "381/381 [==============================] - 0s 127us/sample - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.0824 - val_accuracy: 0.9840\n",
      "Epoch 497/500\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 498/500\n",
      "381/381 [==============================] - 0s 320us/sample - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0824 - val_accuracy: 0.9840\n",
      "Epoch 499/500\n",
      "381/381 [==============================] - 0s 354us/sample - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0824 - val_accuracy: 0.9840\n",
      "Epoch 500/500\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0825 - val_accuracy: 0.9840\n",
      "381/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 57us/sample - loss: 0.0448 - accuracy: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: [0.04998450628494027, 0.984252]\n",
      "188/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 75us/sample - loss: 0.1906 - accuracy: 0.9840\n",
      "Test score: [0.08247049715607724, 0.9840425]\n"
     ]
    }
   ],
   "source": [
    "# Now all the fun Tensorflow stuff\n",
    "# Build the model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Alternatively, you can do:\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n",
    "\n",
    "# Evalute the model - evaluate() returns loass and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f22bc19c748>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot what's returned by model.fit()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f22bc101be0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy too\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9593228e-01]\n",
      " [9.9968696e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9553776e-01]\n",
      " [9.9439919e-01]\n",
      " [9.9979270e-01]\n",
      " [9.9897039e-01]\n",
      " [9.3138713e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9862540e-01]\n",
      " [9.9770749e-01]\n",
      " [9.9987555e-01]\n",
      " [2.0667911e-04]\n",
      " [9.9975371e-01]\n",
      " [5.3265691e-04]\n",
      " [0.0000000e+00]\n",
      " [2.3841858e-07]\n",
      " [0.0000000e+00]\n",
      " [9.9992609e-01]\n",
      " [1.4730096e-03]\n",
      " [9.9996686e-01]\n",
      " [9.9899852e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9999923e-01]\n",
      " [9.3663174e-01]\n",
      " [7.4505806e-07]\n",
      " [9.9998796e-01]\n",
      " [2.3841858e-07]\n",
      " [9.0769327e-01]\n",
      " [1.6939670e-02]\n",
      " [2.9802322e-08]\n",
      " [9.9453712e-01]\n",
      " [9.9997675e-01]\n",
      " [4.6193600e-06]\n",
      " [8.9406967e-08]\n",
      " [3.6060810e-06]\n",
      " [9.9095106e-01]\n",
      " [9.9999332e-01]\n",
      " [5.9604645e-08]\n",
      " [9.9945438e-01]\n",
      " [9.9955493e-01]\n",
      " [2.0861626e-07]\n",
      " [9.9969345e-01]\n",
      " [5.9604645e-08]\n",
      " [9.5176482e-01]\n",
      " [9.9982786e-01]\n",
      " [8.3070993e-04]\n",
      " [9.9993861e-01]\n",
      " [9.9566066e-01]\n",
      " [1.1423230e-04]\n",
      " [2.0861626e-07]\n",
      " [9.9997103e-01]\n",
      " [9.9974567e-01]\n",
      " [9.9925101e-01]\n",
      " [9.6156514e-01]\n",
      " [9.3552572e-01]\n",
      " [9.9999583e-01]\n",
      " [2.1335483e-04]\n",
      " [2.7626067e-02]\n",
      " [2.3841858e-07]\n",
      " [2.4437904e-06]\n",
      " [9.9818301e-01]\n",
      " [8.1658363e-06]\n",
      " [9.9973738e-01]\n",
      " [9.9972951e-01]\n",
      " [3.1292439e-06]\n",
      " [0.0000000e+00]\n",
      " [9.9995494e-01]\n",
      " [9.9978316e-01]\n",
      " [9.9997211e-01]\n",
      " [8.3466184e-01]\n",
      " [9.9999940e-01]\n",
      " [7.6280487e-01]\n",
      " [9.5802391e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9438119e-01]\n",
      " [8.1341994e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9950659e-01]\n",
      " [3.7252903e-06]\n",
      " [9.9986708e-01]\n",
      " [9.9999785e-01]\n",
      " [9.9994564e-01]\n",
      " [1.4871359e-05]\n",
      " [9.9999958e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9991554e-01]\n",
      " [4.2616904e-02]\n",
      " [9.9998391e-01]\n",
      " [0.0000000e+00]\n",
      " [4.9541295e-01]\n",
      " [9.9995875e-01]\n",
      " [9.8355138e-01]\n",
      " [7.8960299e-01]\n",
      " [9.8510754e-01]\n",
      " [7.5758314e-01]\n",
      " [2.4735928e-06]\n",
      " [7.3032081e-03]\n",
      " [9.9999988e-01]\n",
      " [9.7456306e-01]\n",
      " [8.8092685e-03]\n",
      " [8.0078840e-05]\n",
      " [9.9972320e-01]\n",
      " [7.1811676e-04]\n",
      " [9.8602724e-01]\n",
      " [5.1587820e-05]\n",
      " [9.9963558e-01]\n",
      " [1.7881393e-07]\n",
      " [1.1270338e-01]\n",
      " [9.7986829e-01]\n",
      " [9.8280501e-01]\n",
      " [1.3113022e-06]\n",
      " [9.9471569e-01]\n",
      " [2.9802322e-08]\n",
      " [9.9461997e-01]\n",
      " [9.9999404e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9998844e-01]\n",
      " [1.7809868e-04]\n",
      " [9.9995083e-01]\n",
      " [9.9999893e-01]\n",
      " [2.5452912e-02]\n",
      " [9.9301839e-01]\n",
      " [1.6987324e-05]\n",
      " [9.9890566e-01]\n",
      " [9.9455297e-01]\n",
      " [9.9999982e-01]\n",
      " [4.5490265e-04]\n",
      " [0.0000000e+00]\n",
      " [9.9987495e-01]\n",
      " [9.8934484e-01]\n",
      " [9.5829988e-01]\n",
      " [5.0485134e-05]\n",
      " [3.5762787e-07]\n",
      " [9.1043854e-01]\n",
      " [9.9999815e-01]\n",
      " [9.9999940e-01]\n",
      " [9.9999952e-01]\n",
      " [2.3841858e-07]\n",
      " [6.4144731e-02]\n",
      " [9.5338005e-01]\n",
      " [0.0000000e+00]\n",
      " [1.2240112e-03]\n",
      " [1.6502887e-02]\n",
      " [9.9997133e-01]\n",
      " [3.9485097e-04]\n",
      " [2.0918596e-01]\n",
      " [9.9281788e-01]\n",
      " [9.8897123e-01]\n",
      " [9.9521554e-01]\n",
      " [9.9999309e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9762696e-01]\n",
      " [9.7466993e-01]\n",
      " [9.9957466e-01]\n",
      " [8.8820469e-01]\n",
      " [4.3528795e-01]\n",
      " [9.9460983e-01]\n",
      " [9.9996173e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9974728e-01]\n",
      " [9.9999225e-01]\n",
      " [1.1473894e-04]\n",
      " [9.9439883e-01]\n",
      " [7.3820353e-05]\n",
      " [9.9993694e-01]\n",
      " [0.0000000e+00]\n",
      " [9.9999130e-01]\n",
      " [9.9997866e-01]\n",
      " [9.9979615e-01]\n",
      " [9.8717058e-01]\n",
      " [9.9786764e-01]\n",
      " [9.9936932e-01]\n",
      " [9.9519503e-01]\n",
      " [1.4428794e-03]\n",
      " [9.6054184e-01]\n",
      " [8.7893009e-04]\n",
      " [5.8278441e-04]\n",
      " [2.4288893e-04]\n",
      " [9.9806041e-01]\n",
      " [9.9999875e-01]\n",
      " [9.9970913e-01]\n",
      " [9.9990153e-01]\n",
      " [5.9417486e-03]\n",
      " [9.9999833e-01]\n",
      " [5.1330095e-05]\n",
      " [0.0000000e+00]\n",
      " [9.9973518e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "P = model.predict(X_test)\n",
    "print(P) # they are ooutputs of the sigmoid, interpreted as probabilities p(y = 1 | x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
